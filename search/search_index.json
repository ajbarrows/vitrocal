{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the repository for the VitroCal project! VitroCal is a Python-based toolbox for analyzing data collected through in vitro calcium imaging. The package is designed to be flexible and user-friendly. Quickstart Install from source git clone git@github.com:mpmbq2/vitrocal.git We recommend creating a virtual environment. cd vitrocal mamba env update -f environment.yml conda activate vitrocal python -m pip install . Example useage datacatalog = catalog.DataCatalog () df = datacatalog.load ( 'data' )","title":"Home"},{"location":"#quickstart","text":"","title":"Quickstart"},{"location":"#install-from-source","text":"git clone git@github.com:mpmbq2/vitrocal.git We recommend creating a virtual environment. cd vitrocal mamba env update -f environment.yml conda activate vitrocal python -m pip install .","title":"Install from source"},{"location":"#example-useage","text":"datacatalog = catalog.DataCatalog () df = datacatalog.load ( 'data' )","title":"Example useage"},{"location":"ParameterTune/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Tune Vitrocal Parameters import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.datasets import catalog , ExcelDataset from vitrocal.preprocessors import StandardPreprocessor from vitrocal.detectors import DerivativeDetector , StandardExtractor from vitrocal.analyzers import StandardAnalyzer Pull out functions from AnalyzeSingle.py and work with them interactively Load example data file def load_data ( fpath : str | os . PathLike , load_args : dict = {}) -& gt ; pd . DataFrame : \"\"\"Load single neuron output file. Args: fpath (str | os.PathLike): Path to single Excel spreadsheet. load_args (dict, optional): Passed to `pd.read_excel()`. Defaults to None. Returns: pd.DataFrame: Dataframe \"\"\" fname = os . path . basename ( fpath ) dataset = ExcelDataset . ExcelDataset ( fpath , load_args ) return dataset . load (), fname df , fname = load_data ( \"./data/01_raw/E Green.xlsx\" ) # df, fname = load_data(\"../data/01_raw/E Green.xlsx\") df . head () 1.0 22.64 14.464 81.846 22.303 5.206 13.008 20.742 14.349 17.126 36.607 41.751 17.911 9.868 20.88 10.595 19.766 19.937 20.41 15.472 4.139 12.641 3.737 23.991 16.657 56.222 47.472 23.007 14.802 7.97 20.108 24.37 33.058 24.077 31.142 48.045 4.048 13.965 4.224 12.127 21.117 25.81 33.489 47.669 43.951 14.707 34.045 29.163 15.43 25.335 37.077 27.778 21.374 18.34 10.955 26.541 14.188 5.778 18.538 10.539 31.391 23.852 5.949 2.388 6.994 15.802 21.772 6.588 2.145 22.27 13.527 11.289 44.445 81.355 14.337 3.839 6.948 10.796 8.582 21.717 10.199 15.498 10.422 16.775 5.592 26.333 6.552 1.031 2.721 3.963 2.223 5.329 6.514 6.255 4.412 9.865 13.243 11.594 2.955 5.279 11.83 11.454 1.953 39.554 10.668 8.264 3.06 2.67 7.782 6.912 4.135 3.493 2.759 17.813 12.834 5.645 18.946 4.36 1.499 8.511 5.149 4.894 11.065 11.329 3.217 0.882 5.814 3.402 9.316 1.932 5.11 3.497 6.546 9.461 0.725 1.468 1.53 4.134 11.567 4.974 14.442 11.604 8.135 4.038 19.026 6.572 17.669 7.024 2.347 23.887 42.383 4.802 7.62 0 2 21.593 13.584 81.234 19.634 4.756 10.206 17.576 14.729 16.779 35.217 41.618 19.212 8.937 20.427 12.039 19.362 16.424 17.91 14.662 3.103 13.366 3.516 19.601 14.624 53.055 44.007 23.285 8.433 7.173 18.944 24.039 29.637 17.613 26.709 46.553 3.52 12.971 4.228 12.194 21.007 23.588 27.889 38.282 28.993 12.29 23.852 26.035 14.566 15.605 34.464 26.539 20.894 20.494 18.519 26.556 12.436 6.443 19.505 9.862 29.412 23.273 5.595 2.979 8.025 14.302 21.887 5.397 1.015 19.727 13.343 12.477 43.971 80.403 14.026 2.846 5.977 11.718 9.285 20.809 10.715 14.934 8.254 14.173 5.373 22.842 7.003 0.878 2.641 3.563 1.921 5.611 4.859 4.924 3.632 9.196 13.053 10.581 2.622 5.616 13.149 12.519 2.3 40.23 10.584 8.951 2.233 2.568 7.167 6.485 3.964 2.842 2.549 12.622 12.272 5.446 15.042 3.629 0.963 5.473 4.442 3.624 9.139 11.867 2.705 0.961 5.715 2.773 8.309 1.829 4.57 3.199 5.413 7.278 0.903 1.153 1.108 4.565 11.981 4.357 12.693 12.665 8.902 3.39 19.026 9.156 16.792 7.568 2.142 25.34 41.388 4.14 7.929 1 3 20.348 13.595 81.041 22.261 5.335 9.868 13.821 14.625 16.988 35.025 41.858 19.988 8.576 19.932 12.599 18.134 15.993 18.343 14.732 3.459 12.605 3.336 21.192 13.157 51.561 42.05 25.224 13.202 6.371 18.256 23.377 29.213 17.994 28.792 47.982 3.696 12.459 3.853 12.135 20.147 28.378 26.521 36.913 28.516 11.704 25.329 26.761 14.345 14.652 33.582 25.009 21.346 22.997 31.845 26.839 12.672 6.858 18.005 9.072 30.19 23.627 5.674 3.332 8.278 17.891 20.573 5.641 1.513 21.549 13.617 11.852 43.506 81.232 14.604 3.07 5.809 11.423 9.95 21.805 11.494 15.252 7.57 13.447 5.04 21.396 6.222 0.932 2.949 3.08 2.606 5.543 4.813 4.904 4.357 9.404 12.882 11.11 2.519 8.492 8.275 9.134 2.051 40.337 10.048 12.379 2.648 2.789 7.503 6.553 3.921 2.906 2.929 16.767 11.948 4.964 14.949 3.739 0.771 5.646 3.79 3.478 9.129 10.963 2.029 0.931 5.665 2.127 10.181 1.671 4.47 3.242 5.476 7.972 0.841 1.459 1.115 3.671 12.008 3.735 12.307 12.157 11.045 4.179 18.215 7.307 17.28 7.383 2.056 27.561 41.679 3.816 6.994 2 4 22.938 13.941 81.42 21.579 5.41 9.857 13.642 14.422 16.672 36.755 42.189 17.823 8.742 20.371 12.414 20.368 15.031 18.836 15.535 3.614 13.246 4.64 23.625 13.159 49.022 44.062 23.184 15.562 7.82 19.547 23.16 30.782 17.573 31.105 50.289 3.798 16.024 4.203 13.754 18.941 25.104 25.906 50.987 36.556 12.653 40.189 28.196 14.98 20.615 33.157 24.692 21.14 18.301 11.646 32.98 14.338 6.791 18.613 8.52 31.369 23.359 6.022 2.82 6.986 22.005 23.624 6.034 1.418 20.523 13.947 11.756 43.623 80.777 15.209 2.846 6 15.331 11.741 21.113 10.529 14.4 8.578 15.43 4.171 25.491 6.243 0.745 2.386 3.217 2.791 6.689 5.775 5.35 4.139 8.47 13.114 11.333 2.758 6.515 11.45 9.275 2.354 40.311 11.358 8.615 2.858 2.818 6.747 6.591 4.316 2.173 2.959 11.822 11.904 4.558 22.492 3.313 1.335 5.819 3.896 3.69 9.771 10.027 2.282 0.813 5.769 2.367 10.986 1.943 4.317 3.32 5.56 8.638 0.83 2.032 1 3.933 11.231 3.534 14.448 11.857 7.908 3.982 19.623 7.675 16.628 7.272 2.002 23.3 41.452 3.906 7.85 3 5 20.889 12.441 81.222 20.25 5.081 11.525 12.387 13.078 16.708 36.005 43.322 18.191 8.457 20.146 13.188 19.511 14.888 18.262 15.401 3.946 13.002 3.573 18.932 12.759 50.234 41.34 23.786 9.233 6.975 19.435 23.023 27.475 16.595 28.741 54.258 4.17 17.441 4.819 14.448 20.308 25.515 37.709 51.115 34.365 16.798 34.206 28.043 15.964 21.641 34.325 25.546 22.569 22.824 29.187 25.185 13.911 4.314 17.976 9.276 29.437 22.496 6.233 3.011 7.956 18.768 21.349 4.718 1.138 20.24 14.065 11.81 43.708 81.537 15.271 3.692 6.439 11.275 9.536 21.072 11.529 12.211 8.117 17.596 5.169 26.095 6.788 0.879 3.225 3.495 2.627 5.854 5.248 4.984 4.253 8.541 12.895 11.912 2.357 5.085 8.408 13.811 1.591 39.343 11.265 12.611 2.801 4.18 7.086 6.418 4.321 3.928 3.797 16.494 11.794 4.77 16.438 2.747 0.815 5.681 3.866 3.916 9.174 10.751 4.593 1.064 6.226 2.389 8.443 2.089 4.551 3.39 5.217 8.226 1.135 1.486 1.592 3.765 11.472 2.677 14.847 12.522 8.995 4.201 19.561 5.383 20.522 7.516 1.527 19.236 46.553 4.277 7.748 4 6 21.691 14.711 81.017 21.015 5.553 11.386 17.477 13.776 16.634 36.942 42.03 18.863 8.603 19.629 13.885 19.031 19.595 19.676 15.528 4.066 14.426 4.07 22.118 12.436 50.539 42.4 23.164 15.014 8.122 18.742 22.986 28.414 18.06 28.311 50.209 4.213 14.686 5.397 17.018 19.74 24.293 23.319 31.575 40.299 14.855 32.047 29.106 14.938 14.835 32.504 25.384 21.501 22.106 9.479 23.376 14.137 6.36 18.019 9.125 29.301 22.136 5.914 3.18 6.694 13.165 21.07 5.481 1.284 19.299 19.054 14.044 43.553 80.785 15.33 2.736 5.979 11.511 9.841 21.478 11.151 10.596 7.859 15.193 4.594 20.486 8.331 0.751 2.828 3.098 3.185 6.886 5.425 5.854 3.98 8.026 13.825 13.499 2.406 4.373 7.558 7.326 2.463 39.82 10.4 10.677 2.75 5.006 7.67 6.357 3.805 2.748 3.175 12.356 12.252 5.103 15.511 3.082 0.905 5.66 5.07 4.841 7.925 9.645 2.562 0.98 5.865 2.541 7.457 1.893 4.04 3.15 5.425 9.489 1.224 1.491 1.268 4.267 10.709 2.42 13.957 12.126 9.518 3.926 19.548 5.114 18.126 7.079 1.802 23.3 45.417 4.044 7.735 Note: you want to be super careful about loading your files and looking at them first. These files don't have a header, and sometimes they have numbered rows like this one. load_args = { 'header' : None , 'index_col' : 0 } # df, fname = load_data(\"../data/01_raw/E Green.xlsx\", load_args) df , fname = load_data ( \"./data/01_raw/E Green.xlsx\" , load_args ) Vitrocal is organized into three distinct modules for data analysis: * vitrocal.preprocessors * vitrocal.detectors * vitrocal.analyzers You'll want to explore the parameter space for each of these individually and assess the impacts different parameter combinations have on your data. See the documentation for details. Preprocess # change these fps = 1 / 2.5 bleach_period = 60 filter_frequency = None baseline_threshold = 10 # percent preprocess_window_size = 60 # seconds # instantiate the StandardPreprocess object with these parameters preprocessor = StandardPreprocessor ( frames_per_second = 1 / 2.5 , bleach_period = bleach_period , filter_frequency = filter_frequency , baseline_threshold = baseline_threshold , window_size = preprocess_window_size ) # call the object's `preprocess` method # see the documentation for other methods available processed = preprocessor . preprocess ( df ) No filter applied. Detect and Extract # change this threshold = 20 # percent detector = DerivativeDetector ( threshold ) detected = detector . detect ( processed ) Extract Note: the StandardExtractor class has a detect_and_extract method # change these window = ( 3 , 30 ) # seconds before and after threshold = 20 # percent extractor = StandardExtractor ( window = window , frames_per_second = fps , # defined above threshold = threshold ) events = extractor . extract ( processed , detected ) With FPS = 0.4, a window of (3, 30) seconds captures 1 frame(s) before and 12 frame(s) after each event. /Users/tony/Documents/phd/projects/other/vitrocal/vitrocal/detectors.py:137: PerformanceWarning: DataFrame is highly fragmented. This is usually the result of calling `frame.insert` many times, which has poor performance. Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()` identified[identified is False] = np.NaN # non-events Note: this method returns events as a Python dictionary. You can examine individual events, if you like: roi = 2 # events[roi] Analyze # change these upper_decay_bound = 0.8 # proportion lower_decay_bound = 0.2 # proportion analyzer = StandardAnalyzer ( upper_decay_bound = upper_decay_bound , lower_decay_bound = lower_decay_bound ) result , avg_result = analyzer . analyze ( events ) result . head () roi event peak upper lower decay 0 2 1 27.2195 21.2979 2.42369 18.8742 0 5 1 21.8511 6.71749 -3.25337 9.97087 1 5 2 38.5962 15.0923 1.50109 13.5912 2 5 3 37.8041 21.5407 1.03699 20.5037 3 5 4 28.5376 17.3164 nan nan avg_result . head () roi total_events average_peak average_decay 0 2 1 27.2195 18.8742 1 5 8 35.1237 14.3551 2 6 20 52.5964 21.5584 3 7 29 67.1418 30.6436 4 13 6 29.6881 14.3257 global_average , roi_average , event_data = analyzer . find_average_event ( events ) global_average . to_csv ( \"./data/02_output/global_average.csv\" ) roi_average . to_csv ( \"./data/02_output/roi_average.csv\" ) event_data . to_csv ( \"./data/02_output/event_data.csv\" ) # save results # pd.to_pickle(events, \"./data/02_output/demo_events.pkl\") # python dictionary # pd.to_pickle(analyzer, \"./data/02_output/demo_analyzer.pkl\") # python object result . to_csv ( \"./data/02_output/demo_results.csv\" ) avg_result . to_csv ( \"./data/02_output/demo_avg_results.csv\" )","title":"Example Analysis"},{"location":"ParameterTune/#tune-vitrocal-parameters","text":"import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.datasets import catalog , ExcelDataset from vitrocal.preprocessors import StandardPreprocessor from vitrocal.detectors import DerivativeDetector , StandardExtractor from vitrocal.analyzers import StandardAnalyzer Pull out functions from AnalyzeSingle.py and work with them interactively","title":"Tune Vitrocal Parameters"},{"location":"ParameterTune/#load-example-data-file","text":"def load_data ( fpath : str | os . PathLike , load_args : dict = {}) -& gt ; pd . DataFrame : \"\"\"Load single neuron output file. Args: fpath (str | os.PathLike): Path to single Excel spreadsheet. load_args (dict, optional): Passed to `pd.read_excel()`. Defaults to None. Returns: pd.DataFrame: Dataframe \"\"\" fname = os . path . basename ( fpath ) dataset = ExcelDataset . ExcelDataset ( fpath , load_args ) return dataset . load (), fname df , fname = load_data ( \"./data/01_raw/E Green.xlsx\" ) # df, fname = load_data(\"../data/01_raw/E Green.xlsx\") df . head () 1.0 22.64 14.464 81.846 22.303 5.206 13.008 20.742 14.349 17.126 36.607 41.751 17.911 9.868 20.88 10.595 19.766 19.937 20.41 15.472 4.139 12.641 3.737 23.991 16.657 56.222 47.472 23.007 14.802 7.97 20.108 24.37 33.058 24.077 31.142 48.045 4.048 13.965 4.224 12.127 21.117 25.81 33.489 47.669 43.951 14.707 34.045 29.163 15.43 25.335 37.077 27.778 21.374 18.34 10.955 26.541 14.188 5.778 18.538 10.539 31.391 23.852 5.949 2.388 6.994 15.802 21.772 6.588 2.145 22.27 13.527 11.289 44.445 81.355 14.337 3.839 6.948 10.796 8.582 21.717 10.199 15.498 10.422 16.775 5.592 26.333 6.552 1.031 2.721 3.963 2.223 5.329 6.514 6.255 4.412 9.865 13.243 11.594 2.955 5.279 11.83 11.454 1.953 39.554 10.668 8.264 3.06 2.67 7.782 6.912 4.135 3.493 2.759 17.813 12.834 5.645 18.946 4.36 1.499 8.511 5.149 4.894 11.065 11.329 3.217 0.882 5.814 3.402 9.316 1.932 5.11 3.497 6.546 9.461 0.725 1.468 1.53 4.134 11.567 4.974 14.442 11.604 8.135 4.038 19.026 6.572 17.669 7.024 2.347 23.887 42.383 4.802 7.62 0 2 21.593 13.584 81.234 19.634 4.756 10.206 17.576 14.729 16.779 35.217 41.618 19.212 8.937 20.427 12.039 19.362 16.424 17.91 14.662 3.103 13.366 3.516 19.601 14.624 53.055 44.007 23.285 8.433 7.173 18.944 24.039 29.637 17.613 26.709 46.553 3.52 12.971 4.228 12.194 21.007 23.588 27.889 38.282 28.993 12.29 23.852 26.035 14.566 15.605 34.464 26.539 20.894 20.494 18.519 26.556 12.436 6.443 19.505 9.862 29.412 23.273 5.595 2.979 8.025 14.302 21.887 5.397 1.015 19.727 13.343 12.477 43.971 80.403 14.026 2.846 5.977 11.718 9.285 20.809 10.715 14.934 8.254 14.173 5.373 22.842 7.003 0.878 2.641 3.563 1.921 5.611 4.859 4.924 3.632 9.196 13.053 10.581 2.622 5.616 13.149 12.519 2.3 40.23 10.584 8.951 2.233 2.568 7.167 6.485 3.964 2.842 2.549 12.622 12.272 5.446 15.042 3.629 0.963 5.473 4.442 3.624 9.139 11.867 2.705 0.961 5.715 2.773 8.309 1.829 4.57 3.199 5.413 7.278 0.903 1.153 1.108 4.565 11.981 4.357 12.693 12.665 8.902 3.39 19.026 9.156 16.792 7.568 2.142 25.34 41.388 4.14 7.929 1 3 20.348 13.595 81.041 22.261 5.335 9.868 13.821 14.625 16.988 35.025 41.858 19.988 8.576 19.932 12.599 18.134 15.993 18.343 14.732 3.459 12.605 3.336 21.192 13.157 51.561 42.05 25.224 13.202 6.371 18.256 23.377 29.213 17.994 28.792 47.982 3.696 12.459 3.853 12.135 20.147 28.378 26.521 36.913 28.516 11.704 25.329 26.761 14.345 14.652 33.582 25.009 21.346 22.997 31.845 26.839 12.672 6.858 18.005 9.072 30.19 23.627 5.674 3.332 8.278 17.891 20.573 5.641 1.513 21.549 13.617 11.852 43.506 81.232 14.604 3.07 5.809 11.423 9.95 21.805 11.494 15.252 7.57 13.447 5.04 21.396 6.222 0.932 2.949 3.08 2.606 5.543 4.813 4.904 4.357 9.404 12.882 11.11 2.519 8.492 8.275 9.134 2.051 40.337 10.048 12.379 2.648 2.789 7.503 6.553 3.921 2.906 2.929 16.767 11.948 4.964 14.949 3.739 0.771 5.646 3.79 3.478 9.129 10.963 2.029 0.931 5.665 2.127 10.181 1.671 4.47 3.242 5.476 7.972 0.841 1.459 1.115 3.671 12.008 3.735 12.307 12.157 11.045 4.179 18.215 7.307 17.28 7.383 2.056 27.561 41.679 3.816 6.994 2 4 22.938 13.941 81.42 21.579 5.41 9.857 13.642 14.422 16.672 36.755 42.189 17.823 8.742 20.371 12.414 20.368 15.031 18.836 15.535 3.614 13.246 4.64 23.625 13.159 49.022 44.062 23.184 15.562 7.82 19.547 23.16 30.782 17.573 31.105 50.289 3.798 16.024 4.203 13.754 18.941 25.104 25.906 50.987 36.556 12.653 40.189 28.196 14.98 20.615 33.157 24.692 21.14 18.301 11.646 32.98 14.338 6.791 18.613 8.52 31.369 23.359 6.022 2.82 6.986 22.005 23.624 6.034 1.418 20.523 13.947 11.756 43.623 80.777 15.209 2.846 6 15.331 11.741 21.113 10.529 14.4 8.578 15.43 4.171 25.491 6.243 0.745 2.386 3.217 2.791 6.689 5.775 5.35 4.139 8.47 13.114 11.333 2.758 6.515 11.45 9.275 2.354 40.311 11.358 8.615 2.858 2.818 6.747 6.591 4.316 2.173 2.959 11.822 11.904 4.558 22.492 3.313 1.335 5.819 3.896 3.69 9.771 10.027 2.282 0.813 5.769 2.367 10.986 1.943 4.317 3.32 5.56 8.638 0.83 2.032 1 3.933 11.231 3.534 14.448 11.857 7.908 3.982 19.623 7.675 16.628 7.272 2.002 23.3 41.452 3.906 7.85 3 5 20.889 12.441 81.222 20.25 5.081 11.525 12.387 13.078 16.708 36.005 43.322 18.191 8.457 20.146 13.188 19.511 14.888 18.262 15.401 3.946 13.002 3.573 18.932 12.759 50.234 41.34 23.786 9.233 6.975 19.435 23.023 27.475 16.595 28.741 54.258 4.17 17.441 4.819 14.448 20.308 25.515 37.709 51.115 34.365 16.798 34.206 28.043 15.964 21.641 34.325 25.546 22.569 22.824 29.187 25.185 13.911 4.314 17.976 9.276 29.437 22.496 6.233 3.011 7.956 18.768 21.349 4.718 1.138 20.24 14.065 11.81 43.708 81.537 15.271 3.692 6.439 11.275 9.536 21.072 11.529 12.211 8.117 17.596 5.169 26.095 6.788 0.879 3.225 3.495 2.627 5.854 5.248 4.984 4.253 8.541 12.895 11.912 2.357 5.085 8.408 13.811 1.591 39.343 11.265 12.611 2.801 4.18 7.086 6.418 4.321 3.928 3.797 16.494 11.794 4.77 16.438 2.747 0.815 5.681 3.866 3.916 9.174 10.751 4.593 1.064 6.226 2.389 8.443 2.089 4.551 3.39 5.217 8.226 1.135 1.486 1.592 3.765 11.472 2.677 14.847 12.522 8.995 4.201 19.561 5.383 20.522 7.516 1.527 19.236 46.553 4.277 7.748 4 6 21.691 14.711 81.017 21.015 5.553 11.386 17.477 13.776 16.634 36.942 42.03 18.863 8.603 19.629 13.885 19.031 19.595 19.676 15.528 4.066 14.426 4.07 22.118 12.436 50.539 42.4 23.164 15.014 8.122 18.742 22.986 28.414 18.06 28.311 50.209 4.213 14.686 5.397 17.018 19.74 24.293 23.319 31.575 40.299 14.855 32.047 29.106 14.938 14.835 32.504 25.384 21.501 22.106 9.479 23.376 14.137 6.36 18.019 9.125 29.301 22.136 5.914 3.18 6.694 13.165 21.07 5.481 1.284 19.299 19.054 14.044 43.553 80.785 15.33 2.736 5.979 11.511 9.841 21.478 11.151 10.596 7.859 15.193 4.594 20.486 8.331 0.751 2.828 3.098 3.185 6.886 5.425 5.854 3.98 8.026 13.825 13.499 2.406 4.373 7.558 7.326 2.463 39.82 10.4 10.677 2.75 5.006 7.67 6.357 3.805 2.748 3.175 12.356 12.252 5.103 15.511 3.082 0.905 5.66 5.07 4.841 7.925 9.645 2.562 0.98 5.865 2.541 7.457 1.893 4.04 3.15 5.425 9.489 1.224 1.491 1.268 4.267 10.709 2.42 13.957 12.126 9.518 3.926 19.548 5.114 18.126 7.079 1.802 23.3 45.417 4.044 7.735 Note: you want to be super careful about loading your files and looking at them first. These files don't have a header, and sometimes they have numbered rows like this one. load_args = { 'header' : None , 'index_col' : 0 } # df, fname = load_data(\"../data/01_raw/E Green.xlsx\", load_args) df , fname = load_data ( \"./data/01_raw/E Green.xlsx\" , load_args ) Vitrocal is organized into three distinct modules for data analysis: * vitrocal.preprocessors * vitrocal.detectors * vitrocal.analyzers You'll want to explore the parameter space for each of these individually and assess the impacts different parameter combinations have on your data. See the documentation for details.","title":"Load example data file"},{"location":"ParameterTune/#preprocess","text":"# change these fps = 1 / 2.5 bleach_period = 60 filter_frequency = None baseline_threshold = 10 # percent preprocess_window_size = 60 # seconds # instantiate the StandardPreprocess object with these parameters preprocessor = StandardPreprocessor ( frames_per_second = 1 / 2.5 , bleach_period = bleach_period , filter_frequency = filter_frequency , baseline_threshold = baseline_threshold , window_size = preprocess_window_size ) # call the object's `preprocess` method # see the documentation for other methods available processed = preprocessor . preprocess ( df ) No filter applied.","title":"Preprocess"},{"location":"ParameterTune/#detect-and-extract","text":"# change this threshold = 20 # percent detector = DerivativeDetector ( threshold ) detected = detector . detect ( processed )","title":"Detect and Extract"},{"location":"ParameterTune/#extract","text":"Note: the StandardExtractor class has a detect_and_extract method # change these window = ( 3 , 30 ) # seconds before and after threshold = 20 # percent extractor = StandardExtractor ( window = window , frames_per_second = fps , # defined above threshold = threshold ) events = extractor . extract ( processed , detected ) With FPS = 0.4, a window of (3, 30) seconds captures 1 frame(s) before and 12 frame(s) after each event. /Users/tony/Documents/phd/projects/other/vitrocal/vitrocal/detectors.py:137: PerformanceWarning: DataFrame is highly fragmented. This is usually the result of calling `frame.insert` many times, which has poor performance. Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()` identified[identified is False] = np.NaN # non-events Note: this method returns events as a Python dictionary. You can examine individual events, if you like: roi = 2 # events[roi]","title":"Extract"},{"location":"ParameterTune/#analyze","text":"# change these upper_decay_bound = 0.8 # proportion lower_decay_bound = 0.2 # proportion analyzer = StandardAnalyzer ( upper_decay_bound = upper_decay_bound , lower_decay_bound = lower_decay_bound ) result , avg_result = analyzer . analyze ( events ) result . head () roi event peak upper lower decay 0 2 1 27.2195 21.2979 2.42369 18.8742 0 5 1 21.8511 6.71749 -3.25337 9.97087 1 5 2 38.5962 15.0923 1.50109 13.5912 2 5 3 37.8041 21.5407 1.03699 20.5037 3 5 4 28.5376 17.3164 nan nan avg_result . head () roi total_events average_peak average_decay 0 2 1 27.2195 18.8742 1 5 8 35.1237 14.3551 2 6 20 52.5964 21.5584 3 7 29 67.1418 30.6436 4 13 6 29.6881 14.3257 global_average , roi_average , event_data = analyzer . find_average_event ( events ) global_average . to_csv ( \"./data/02_output/global_average.csv\" ) roi_average . to_csv ( \"./data/02_output/roi_average.csv\" ) event_data . to_csv ( \"./data/02_output/event_data.csv\" ) # save results # pd.to_pickle(events, \"./data/02_output/demo_events.pkl\") # python dictionary # pd.to_pickle(analyzer, \"./data/02_output/demo_analyzer.pkl\") # python object result . to_csv ( \"./data/02_output/demo_results.csv\" ) avg_result . to_csv ( \"./data/02_output/demo_avg_results.csv\" )","title":"Analyze"},{"location":"Plotting/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Example Vitrocal Plotting This is meant to be a surface-level example of what an author might want to do. See that Matplotlib and Seaborn documentation for more details. import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.plotting import plot_events , plot_average_event Load results from the Parameter Tune example # events = pd.read_pickle(\"./data/02_output/demo_events.pkl\") # python dictionary # analyzer = pd.read_pickle(\"./data/02_output/demo_analyzer.pkl\") # python object events = pd . read_csv ( \"./data/02_output/event_data.csv\" ) roi_average = pd . read_csv ( \"./data/02_output/roi_average.csv\" ) global_average = pd . read_csv ( \"./data/02_output/global_average.csv\" ) result = pd . read_csv ( \"./data/02_output/demo_results.csv\" ) avg_result = pd . read_csv ( \"./data/02_output/demo_avg_results.csv\" ) Plot average traces plot_average_event ( global_average . head (), # only plot the first 5 seconds title = \"Average Detected Event\" , ylabel = \"df/F\" , xlabel = \"Time (s)\" , line_color = \"black\" , fill_color = 'C0' ) selected_roi = 15 plot_average_event ( roi_average [ roi_average [ 'roi' ] == selected_roi ], title = 'Average Event for ROI {} ' . format ( selected_roi )) Plot Event Counts # add arbitrary goupings for demonstration arbitrary_groups = np . repeat ([ 'group1' , 'group2' , 'group3' ], len ( avg_result ) / 3 ) avg_result [ 'group' ] = arbitrary_groups sns . pointplot ( data = avg_result , x = 'average_peak' , y = 'group' , hue = 'group' ) <Axes: xlabel='average_peak', ylabel='group'> # alternatively sns . histplot ( data = avg_result , x = 'average_peak' , hue = 'group' , kde = True ) <Axes: xlabel='average_peak', ylabel='Count'>","title":"Example Plotting"},{"location":"Plotting/#example-vitrocal-plotting","text":"This is meant to be a surface-level example of what an author might want to do. See that Matplotlib and Seaborn documentation for more details. import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.plotting import plot_events , plot_average_event Load results from the Parameter Tune example # events = pd.read_pickle(\"./data/02_output/demo_events.pkl\") # python dictionary # analyzer = pd.read_pickle(\"./data/02_output/demo_analyzer.pkl\") # python object events = pd . read_csv ( \"./data/02_output/event_data.csv\" ) roi_average = pd . read_csv ( \"./data/02_output/roi_average.csv\" ) global_average = pd . read_csv ( \"./data/02_output/global_average.csv\" ) result = pd . read_csv ( \"./data/02_output/demo_results.csv\" ) avg_result = pd . read_csv ( \"./data/02_output/demo_avg_results.csv\" )","title":"Example Vitrocal Plotting"},{"location":"Plotting/#plot-average-traces","text":"plot_average_event ( global_average . head (), # only plot the first 5 seconds title = \"Average Detected Event\" , ylabel = \"df/F\" , xlabel = \"Time (s)\" , line_color = \"black\" , fill_color = 'C0' ) selected_roi = 15 plot_average_event ( roi_average [ roi_average [ 'roi' ] == selected_roi ], title = 'Average Event for ROI {} ' . format ( selected_roi ))","title":"Plot average traces"},{"location":"Plotting/#plot-event-counts","text":"# add arbitrary goupings for demonstration arbitrary_groups = np . repeat ([ 'group1' , 'group2' , 'group3' ], len ( avg_result ) / 3 ) avg_result [ 'group' ] = arbitrary_groups sns . pointplot ( data = avg_result , x = 'average_peak' , y = 'group' , hue = 'group' ) <Axes: xlabel='average_peak', ylabel='group'> # alternatively sns . histplot ( data = avg_result , x = 'average_peak' , hue = 'group' , kde = True ) <Axes: xlabel='average_peak', ylabel='Count'>","title":"Plot Event Counts"},{"location":"api/","text":"API Reference Top-level API for VitroCal. This is the file from which you can do: from vitrocal import some_function Use it to control the top-level API of your Python data science project. Catalog module for easy access to conf/catalog.yaml . AbstractCatalog Bases: ABC Abstract class for catalog. Source code in vitrocal/datasets/catalog.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class AbstractCatalog ( ABC ): \"\"\"Abstract class for catalog.\"\"\" @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load () load () abstractmethod Define loader for dataset. Returns: \u2013 Method Source code in vitrocal/datasets/catalog.py 20 21 22 23 24 25 26 27 @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load () parse_catalog () abstractmethod Define parser for catalog file. Returns: \u2013 Method. Source code in vitrocal/datasets/catalog.py 11 12 13 14 15 16 17 18 @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () DataCatalog Bases: AbstractCatalog Allows easy access to conf/catalog.yaml . Inspired by https://kedro.org. Source code in vitrocal/datasets/catalog.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class DataCatalog ( AbstractCatalog ): \"\"\"Allows easy access to `conf/catalog.yaml`. Inspired by https://kedro.org. \"\"\" def __init__ ( self , fpath = \"../../conf/catalog.yaml\" ): self . fpath = fpath self . datasets = self . parse_catalog () def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load () load ( dataset ) Loader function. Parameters: dataset \u2013 Valid dataset name. Returns: \u2013 Dataset. Source code in vitrocal/datasets/catalog.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load () parse_catalog () Parse catalog file. Returns: dict ( dict ) \u2013 Dataset dictionary. Source code in vitrocal/datasets/catalog.py 55 56 57 58 59 60 61 62 63 64 def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog ExcelDataset class definition ExcelDataset Bases: AbstractDataset ExcelDataset class. Source code in vitrocal/datasets/ExcelDataset.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ExcelDataset ( AbstractDataset ): \"\"\"ExcelDataset class.\"\"\" def __init__ ( self , filepath : str , load_args = {}): self . _filepath = PurePosixPath ( filepath ) self . _load_args = load_args def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) load () Loader function. Returns: DataFrame \u2013 pd.DataFrame: Dataframe. Source code in vitrocal/datasets/ExcelDataset.py 15 16 17 18 19 20 21 def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) save () Save function. Not yet implemented. Source code in vitrocal/datasets/ExcelDataset.py 23 24 25 26 def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) Abstract dataset classes. AbstractDataset Bases: ABC Abstract class for dataset. Source code in vitrocal/datasets/io.py 6 7 8 9 10 11 12 13 14 15 16 class AbstractDataset ( ABC ): \"\"\"Abstract class for dataset.\"\"\" @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () load () abstractmethod Loader base method. Source code in vitrocal/datasets/io.py 8 9 10 11 @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () save () abstractmethod Saver base method. Source code in vitrocal/datasets/io.py 13 14 15 16 @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () Preprocessor module. StandardPreprocessor Bases: BasePreprocessor Preprocessor object class. Attributes: frames_per_second ( int ) \u2013 Image aquisition rate. Defaults to None. filter_frequency ( float ) \u2013 Lowpass filter frequency (Hz). Defaults to None. filter_order ( int ) \u2013 Order passed to scipy.signal.bessel. Defaults to 1. window_size ( float ) \u2013 Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold ( float ) \u2013 Threshold below which to define baseline values (proportion). Defaults to None. bleach_period ( float ) \u2013 Source code in vitrocal/preprocessors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class StandardPreprocessor ( BasePreprocessor ): \"\"\"Preprocessor object class. Attributes: frames_per_second (int, optional): Image aquisition rate. Defaults to None. filter_frequency (float, optional): Lowpass filter frequency (Hz). Defaults to None. filter_order (int, optional): Order passed to scipy.signal.bessel. Defaults to 1. window_size (float, optional): Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold (float, optional): Threshold below which to define baseline values (proportion). Defaults to None. bleach_period (float, optional): Initial photobleaching period to be removed (seconds). Defaults to 60. \"\"\" def __init__ ( self , frames_per_second : int = None , filter_frequency : float = None , filter_order : int = 1 , window_size : float = 60 , baseline_threshold : float = None , bleach_period : float = 60 , column_minimum : int = None ): self . frames_per_second = frames_per_second self . filter_frequency = filter_frequency self . filter_order = filter_order self . window_size = window_size self . baseline_threshold = baseline_threshold self . bleach_period = bleach_period self . column_minimum = column_minimum def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) def _construct_bessel_filter ( self , filter_frequency : float , filter_order : int ): \"\"\"Apply scipy.signal.bessel filter. See https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.bessel.html Args: filter_frequency (float): Critical frequency. filter_order (int): Order of the filter. Returns: b,a: Numerator (b) and denominator (a) polynomials. \"\"\" # noqa: E501 b , a = bessel ( filter_order , filter_frequency ) return b , a def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100 baseline ( data ) Identify baseline fluoresence using a backward-looking rolling window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] compute_fluoresence_change ( data , baseline ) Compute percent change in flouresence from baseline. (data - baseline) / baseline * 100 Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) input dataframe. baseline ( DataFrame ) \u2013 m (images) x n (trace) baseline dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100 drop_frames ( data ) Drop frames for all traces. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with initial frames (rows) dropped. Source code in vitrocal/preprocessors.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) filter ( data ) Apply filter object backward and forward. Parameters: data ( DataFrame ) \u2013 ROI x image array. Returns: DataFrame \u2013 pd.DataFrame: Filtered output in the same shape as data . Source code in vitrocal/preprocessors.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) preprocess ( data ) Drop frames, filter, baseline, and compute flouresence change. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. Source code in vitrocal/preprocessors.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f Detector and extractor classes for event detection and extraction. DerivativeDetector Bases: BaseDetector Initialize derivative detector object. Attributes: threshold ( float ) \u2013 Minimum threshold (percent) to identify an event. Defaults to 20. Source code in vitrocal/detectors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class DerivativeDetector ( BaseDetector ): \"\"\"Initialize derivative detector object. Attributes: threshold (float, optional): Minimum threshold (percent) to identify an event. Defaults to 20. \"\"\" def __init__ ( self , threshold : float = 20 ): self . threshold = threshold def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold def _compute_derivative ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute element-wise difference. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Derivative dataframe. \"\"\" return data . diff () detect ( data ) Compute derivatives and detect threshold crossings. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. Source code in vitrocal/detectors.py 22 23 24 25 26 27 28 29 30 31 32 33 def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold StandardExtractor Bases: BaseExtractor Initialize event extractor object. Attributes: window ( Tuple [ int ] ) \u2013 Backward and forward window in seconds defining an event. frames_per_second ( int ) \u2013 Image aquisition rate.. Defaults to None. threshold ( float ) \u2013 Minimum percentile to identify an event. Passed to BaseDetector() . Defaults to 20. Source code in vitrocal/detectors.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class StandardExtractor ( BaseExtractor ): \"\"\"Initialize event extractor object. Attributes: window (Tuple[int]): Backward and forward window in seconds defining an event. frames_per_second (int, optional): Image aquisition rate.. Defaults to None. threshold (float, optional): Minimum percentile to identify an event. Passed to `BaseDetector()`. Defaults to 20. \"\"\" def __init__ ( self , window : Tuple [ int ], frames_per_second : int = None , threshold : float = 20 ): self . window = window self . frames_per_second = frames_per_second self . threshold = threshold def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events def _identify_events ( self , detected : pd . DataFrame ): \"\"\"Identify events (where derivative = 0). Args: detected (pd.DataFrame): Dataframe Returns: pd.DataFrame: Dataframe of identified events. \"\"\" identified = detected [ detected . diff () != 0 ] # only keep start of event identified [ identified is False ] = np . NaN # non-events return detected def _convert_window_to_frames ( self ) -> Tuple [ int , int ]: \"\"\"Convert window supplied in FPS to numbers of frames. Returns: Tuple[int, int]: Detection window expressed as numbers of frames backward and forward respectively. \"\"\" fps = self . frames_per_second window = tuple ( int ( w * fps ) for w in self . window ) print (( f \"With FPS = { self . frames_per_second } , a window of \" f \" { self . window } seconds captures { window [ 0 ] } frame(s) \" f \"before and { window [ 1 ] } frame(s) after each event.\" )) return window detect_and_extract ( data ) Compute derivatives and extract events. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: dict ( dict ) \u2013 Dictionary of events. Source code in vitrocal/detectors.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) extract ( data , detected ) Extract events using fixed window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. detected ( DataFrame ) \u2013 dataframe of detected events. Raises: ValueError \u2013 data and detected must be the of the same dimensions. Returns: dict ( dict ) \u2013 Extracted events. Source code in vitrocal/detectors.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events Module for analyzing extracted events. StandardAnalyzer Bases: BaseAnalyzer Initialize analyzer object. Attributes: upper_decay_bound ( float ) \u2013 Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound ( float ) \u2013 Proprtion of data to denote lower bound. Defaults to 0.2. Source code in vitrocal/analyzers.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 class StandardAnalyzer ( BaseAnalyzer ): \"\"\"Initialize analyzer object. Attributes: upper_decay_bound (float, optional): Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound (float, optional): Proprtion of data to denote lower bound. Defaults to 0.2. \"\"\" def __init__ ( self , upper_decay_bound : float = 0.8 , lower_decay_bound : float = 0.2 ): self . upper_decay_bound = upper_decay_bound self . lower_decay_bound = lower_decay_bound def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () # def find_average_event(self, events: dict) -> pd.Series: # \"\"\"Index-wise average events. # Args: # events (dict): Detected events from `StandardExtractor.detect_and_extract()` # Returns: # pd.DataFrame: Index-wise average event. # \"\"\" # combined = pd.Series() # for trac, values in events.items(): # for sequence in values: # tmp = pd.Series(sequence) # combined = pd.concat([combined, tmp], axis=1).agg(\"mean\", axis=1) # return combined.sort_index() def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data analyze ( events , drop_inf = True ) Return dataframe with event counts, peaks, and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: DataFrame \u2013 pd.DataFrame: Summary dataframe. Source code in vitrocal/analyzers.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results count_events ( events ) Count number of events for each trace. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Counts. Source code in vitrocal/analyzers.py 50 51 52 53 54 55 56 57 58 59 60 def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} find_average_decay ( decay ) Return summary metrics for each event grouped by ROI. Parameters: decay ( DataFrame ) \u2013 Output from StandardAnalyzer.find_event_decay() Returns: DataFrame \u2013 pd.DataFrame: Average metrics per ROI. Source code in vitrocal/analyzers.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () find_average_event ( events ) Find average events. Parameters: events ( dict ) \u2013 dictionary of events Returns: combined ( ( DataFrame , DataFrame ) ) \u2013 combined dataframe of quantiles event_data ( ( DataFrame , DataFrame ) ) \u2013 dataframe of events Source code in vitrocal/analyzers.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data find_event_decay ( events ) Find event peaks and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Summary dictionary. Source code in vitrocal/analyzers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary find_event_peaks ( events ) Find peak for each event. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Event peaks. Source code in vitrocal/analyzers.py 62 63 64 65 66 67 68 69 70 71 72 def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} Module for plotting extracted events. plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ) Plots the average detected event with the 25th and 75th percentiles shaded in. Parameters: combined ( DataFrame ) \u2013 A DataFrame with columns 'median', 'q1', and 'q3'. title ( str , default: 'Average Detected Event' ) \u2013 The title of the plot. ylabel ( str , default: 'df/F' ) \u2013 The label for the y-axis. xlabel ( str , default: 'Time' ) \u2013 The label for the x-axis. line_color ( str , default: 'black' ) \u2013 The color of the line. fill_color ( str , default: 'C0' ) \u2013 The color of the fill. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ): \"\"\" Plots the average detected event with the 25th and 75th percentiles shaded in. Args: combined (DataFrame): A DataFrame with columns 'median', 'q1', and 'q3'. title (str): The title of the plot. ylabel (str): The label for the y-axis. xlabel (str): The label for the x-axis. line_color (str): The color of the line. fill_color (str): The color of the fill. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () ax . plot ( combined . index , combined [ 'median' ], linestyle = 'dashed' , color = line_color ) ax . fill_between ( combined . index , combined [ 'q1' ], combined [ 'q3' ], alpha = .25 , color = fill_color ) ax . set_title ( title ) ax . set_ylabel ( ylabel ) ax . set_xlabel ( xlabel ) ax . spines [ 'right' ] . set_visible ( False ) ax . spines [ 'top' ] . set_visible ( False ) ax . spines [ 'left' ] . set_visible ( False ) ax . spines [ 'bottom' ] . set_visible ( False ) ax . set_yticks ([]) ax . set_xticks ([]) plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ) Plots the detected events for a given ROI. Parameters: events_df ( DataFrame ) \u2013 A DataFrame with columns 'roi', 'time', and 'flourescence'. roi ( int , default: 0 ) \u2013 The region of interest to plot. title ( str , default: 'Detected Events for ROI' ) \u2013 The title of the plot. xlab ( str , default: 'Time (s)' ) \u2013 The label for the x-axis. ylab ( str , default: 'dF/F' ) \u2013 The label for the y-axis. color ( str , default: 'C0' ) \u2013 The color of the line. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ): \"\"\" Plots the detected events for a given ROI. Args: events_df (DataFrame): A DataFrame with columns 'roi', 'time', and 'flourescence'. roi (int): The region of interest to plot. title (str): The title of the plot. xlab (str): The label for the x-axis. ylab (str): The label for the y-axis. color (str): The color of the line. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () events = events_df [ events_df [ 'roi' ] == roi ] ax . plot ( events [ 'index' ], events [ 'flourescence' ], color = color ) ax . set_xlabel ( xlab ) ax . set_ylabel ( ylab ) ax . set_title ( title + ' ' + str ( roi ))","title":"API Reference"},{"location":"api/#api-reference","text":"Top-level API for VitroCal. This is the file from which you can do: from vitrocal import some_function Use it to control the top-level API of your Python data science project. Catalog module for easy access to conf/catalog.yaml .","title":"API Reference"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog","text":"Bases: ABC Abstract class for catalog. Source code in vitrocal/datasets/catalog.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class AbstractCatalog ( ABC ): \"\"\"Abstract class for catalog.\"\"\" @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load ()","title":"AbstractCatalog"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog.load","text":"Define loader for dataset. Returns: \u2013 Method Source code in vitrocal/datasets/catalog.py 20 21 22 23 24 25 26 27 @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load ()","title":"load"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog.parse_catalog","text":"Define parser for catalog file. Returns: \u2013 Method. Source code in vitrocal/datasets/catalog.py 11 12 13 14 15 16 17 18 @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog ()","title":"parse_catalog"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog","text":"Bases: AbstractCatalog Allows easy access to conf/catalog.yaml . Inspired by https://kedro.org. Source code in vitrocal/datasets/catalog.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class DataCatalog ( AbstractCatalog ): \"\"\"Allows easy access to `conf/catalog.yaml`. Inspired by https://kedro.org. \"\"\" def __init__ ( self , fpath = \"../../conf/catalog.yaml\" ): self . fpath = fpath self . datasets = self . parse_catalog () def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load ()","title":"DataCatalog"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog.load","text":"Loader function. Parameters: dataset \u2013 Valid dataset name. Returns: \u2013 Dataset. Source code in vitrocal/datasets/catalog.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load ()","title":"load"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog.parse_catalog","text":"Parse catalog file. Returns: dict ( dict ) \u2013 Dataset dictionary. Source code in vitrocal/datasets/catalog.py 55 56 57 58 59 60 61 62 63 64 def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog ExcelDataset class definition","title":"parse_catalog"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset","text":"Bases: AbstractDataset ExcelDataset class. Source code in vitrocal/datasets/ExcelDataset.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ExcelDataset ( AbstractDataset ): \"\"\"ExcelDataset class.\"\"\" def __init__ ( self , filepath : str , load_args = {}): self . _filepath = PurePosixPath ( filepath ) self . _load_args = load_args def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError )","title":"ExcelDataset"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset.load","text":"Loader function. Returns: DataFrame \u2013 pd.DataFrame: Dataframe. Source code in vitrocal/datasets/ExcelDataset.py 15 16 17 18 19 20 21 def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args )","title":"load"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset.save","text":"Save function. Not yet implemented. Source code in vitrocal/datasets/ExcelDataset.py 23 24 25 26 def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) Abstract dataset classes.","title":"save"},{"location":"api/#vitrocal.datasets.io.AbstractDataset","text":"Bases: ABC Abstract class for dataset. Source code in vitrocal/datasets/io.py 6 7 8 9 10 11 12 13 14 15 16 class AbstractDataset ( ABC ): \"\"\"Abstract class for dataset.\"\"\" @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save ()","title":"AbstractDataset"},{"location":"api/#vitrocal.datasets.io.AbstractDataset.load","text":"Loader base method. Source code in vitrocal/datasets/io.py 8 9 10 11 @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load ()","title":"load"},{"location":"api/#vitrocal.datasets.io.AbstractDataset.save","text":"Saver base method. Source code in vitrocal/datasets/io.py 13 14 15 16 @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () Preprocessor module.","title":"save"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor","text":"Bases: BasePreprocessor Preprocessor object class. Attributes: frames_per_second ( int ) \u2013 Image aquisition rate. Defaults to None. filter_frequency ( float ) \u2013 Lowpass filter frequency (Hz). Defaults to None. filter_order ( int ) \u2013 Order passed to scipy.signal.bessel. Defaults to 1. window_size ( float ) \u2013 Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold ( float ) \u2013 Threshold below which to define baseline values (proportion). Defaults to None. bleach_period ( float ) \u2013 Source code in vitrocal/preprocessors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class StandardPreprocessor ( BasePreprocessor ): \"\"\"Preprocessor object class. Attributes: frames_per_second (int, optional): Image aquisition rate. Defaults to None. filter_frequency (float, optional): Lowpass filter frequency (Hz). Defaults to None. filter_order (int, optional): Order passed to scipy.signal.bessel. Defaults to 1. window_size (float, optional): Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold (float, optional): Threshold below which to define baseline values (proportion). Defaults to None. bleach_period (float, optional): Initial photobleaching period to be removed (seconds). Defaults to 60. \"\"\" def __init__ ( self , frames_per_second : int = None , filter_frequency : float = None , filter_order : int = 1 , window_size : float = 60 , baseline_threshold : float = None , bleach_period : float = 60 , column_minimum : int = None ): self . frames_per_second = frames_per_second self . filter_frequency = filter_frequency self . filter_order = filter_order self . window_size = window_size self . baseline_threshold = baseline_threshold self . bleach_period = bleach_period self . column_minimum = column_minimum def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) def _construct_bessel_filter ( self , filter_frequency : float , filter_order : int ): \"\"\"Apply scipy.signal.bessel filter. See https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.bessel.html Args: filter_frequency (float): Critical frequency. filter_order (int): Order of the filter. Returns: b,a: Numerator (b) and denominator (a) polynomials. \"\"\" # noqa: E501 b , a = bessel ( filter_order , filter_frequency ) return b , a def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100","title":"StandardPreprocessor"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.baseline","text":"Identify baseline fluoresence using a backward-looking rolling window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ]","title":"baseline"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.compute_fluoresence_change","text":"Compute percent change in flouresence from baseline. (data - baseline) / baseline * 100 Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) input dataframe. baseline ( DataFrame ) \u2013 m (images) x n (trace) baseline dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100","title":"compute_fluoresence_change"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.drop_frames","text":"Drop frames for all traces. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with initial frames (rows) dropped. Source code in vitrocal/preprocessors.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) )","title":"drop_frames"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.filter","text":"Apply filter object backward and forward. Parameters: data ( DataFrame ) \u2013 ROI x image array. Returns: DataFrame \u2013 pd.DataFrame: Filtered output in the same shape as data . Source code in vitrocal/preprocessors.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered )","title":"filter"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.preprocess","text":"Drop frames, filter, baseline, and compute flouresence change. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. Source code in vitrocal/preprocessors.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f Detector and extractor classes for event detection and extraction.","title":"preprocess"},{"location":"api/#vitrocal.detectors.DerivativeDetector","text":"Bases: BaseDetector Initialize derivative detector object. Attributes: threshold ( float ) \u2013 Minimum threshold (percent) to identify an event. Defaults to 20. Source code in vitrocal/detectors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class DerivativeDetector ( BaseDetector ): \"\"\"Initialize derivative detector object. Attributes: threshold (float, optional): Minimum threshold (percent) to identify an event. Defaults to 20. \"\"\" def __init__ ( self , threshold : float = 20 ): self . threshold = threshold def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold def _compute_derivative ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute element-wise difference. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Derivative dataframe. \"\"\" return data . diff ()","title":"DerivativeDetector"},{"location":"api/#vitrocal.detectors.DerivativeDetector.detect","text":"Compute derivatives and detect threshold crossings. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. Source code in vitrocal/detectors.py 22 23 24 25 26 27 28 29 30 31 32 33 def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold","title":"detect"},{"location":"api/#vitrocal.detectors.StandardExtractor","text":"Bases: BaseExtractor Initialize event extractor object. Attributes: window ( Tuple [ int ] ) \u2013 Backward and forward window in seconds defining an event. frames_per_second ( int ) \u2013 Image aquisition rate.. Defaults to None. threshold ( float ) \u2013 Minimum percentile to identify an event. Passed to BaseDetector() . Defaults to 20. Source code in vitrocal/detectors.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class StandardExtractor ( BaseExtractor ): \"\"\"Initialize event extractor object. Attributes: window (Tuple[int]): Backward and forward window in seconds defining an event. frames_per_second (int, optional): Image aquisition rate.. Defaults to None. threshold (float, optional): Minimum percentile to identify an event. Passed to `BaseDetector()`. Defaults to 20. \"\"\" def __init__ ( self , window : Tuple [ int ], frames_per_second : int = None , threshold : float = 20 ): self . window = window self . frames_per_second = frames_per_second self . threshold = threshold def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events def _identify_events ( self , detected : pd . DataFrame ): \"\"\"Identify events (where derivative = 0). Args: detected (pd.DataFrame): Dataframe Returns: pd.DataFrame: Dataframe of identified events. \"\"\" identified = detected [ detected . diff () != 0 ] # only keep start of event identified [ identified is False ] = np . NaN # non-events return detected def _convert_window_to_frames ( self ) -> Tuple [ int , int ]: \"\"\"Convert window supplied in FPS to numbers of frames. Returns: Tuple[int, int]: Detection window expressed as numbers of frames backward and forward respectively. \"\"\" fps = self . frames_per_second window = tuple ( int ( w * fps ) for w in self . window ) print (( f \"With FPS = { self . frames_per_second } , a window of \" f \" { self . window } seconds captures { window [ 0 ] } frame(s) \" f \"before and { window [ 1 ] } frame(s) after each event.\" )) return window","title":"StandardExtractor"},{"location":"api/#vitrocal.detectors.StandardExtractor.detect_and_extract","text":"Compute derivatives and extract events. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: dict ( dict ) \u2013 Dictionary of events. Source code in vitrocal/detectors.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected )","title":"detect_and_extract"},{"location":"api/#vitrocal.detectors.StandardExtractor.extract","text":"Extract events using fixed window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. detected ( DataFrame ) \u2013 dataframe of detected events. Raises: ValueError \u2013 data and detected must be the of the same dimensions. Returns: dict ( dict ) \u2013 Extracted events. Source code in vitrocal/detectors.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events Module for analyzing extracted events.","title":"extract"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer","text":"Bases: BaseAnalyzer Initialize analyzer object. Attributes: upper_decay_bound ( float ) \u2013 Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound ( float ) \u2013 Proprtion of data to denote lower bound. Defaults to 0.2. Source code in vitrocal/analyzers.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 class StandardAnalyzer ( BaseAnalyzer ): \"\"\"Initialize analyzer object. Attributes: upper_decay_bound (float, optional): Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound (float, optional): Proprtion of data to denote lower bound. Defaults to 0.2. \"\"\" def __init__ ( self , upper_decay_bound : float = 0.8 , lower_decay_bound : float = 0.2 ): self . upper_decay_bound = upper_decay_bound self . lower_decay_bound = lower_decay_bound def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () # def find_average_event(self, events: dict) -> pd.Series: # \"\"\"Index-wise average events. # Args: # events (dict): Detected events from `StandardExtractor.detect_and_extract()` # Returns: # pd.DataFrame: Index-wise average event. # \"\"\" # combined = pd.Series() # for trac, values in events.items(): # for sequence in values: # tmp = pd.Series(sequence) # combined = pd.concat([combined, tmp], axis=1).agg(\"mean\", axis=1) # return combined.sort_index() def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data","title":"StandardAnalyzer"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.analyze","text":"Return dataframe with event counts, peaks, and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: DataFrame \u2013 pd.DataFrame: Summary dataframe. Source code in vitrocal/analyzers.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results","title":"analyze"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.count_events","text":"Count number of events for each trace. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Counts. Source code in vitrocal/analyzers.py 50 51 52 53 54 55 56 57 58 59 60 def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()}","title":"count_events"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_average_decay","text":"Return summary metrics for each event grouped by ROI. Parameters: decay ( DataFrame ) \u2013 Output from StandardAnalyzer.find_event_decay() Returns: DataFrame \u2013 pd.DataFrame: Average metrics per ROI. Source code in vitrocal/analyzers.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index ()","title":"find_average_decay"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_average_event","text":"Find average events. Parameters: events ( dict ) \u2013 dictionary of events Returns: combined ( ( DataFrame , DataFrame ) ) \u2013 combined dataframe of quantiles event_data ( ( DataFrame , DataFrame ) ) \u2013 dataframe of events Source code in vitrocal/analyzers.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data","title":"find_average_event"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_event_decay","text":"Find event peaks and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Summary dictionary. Source code in vitrocal/analyzers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary","title":"find_event_decay"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_event_peaks","text":"Find peak for each event. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Event peaks. Source code in vitrocal/analyzers.py 62 63 64 65 66 67 68 69 70 71 72 def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} Module for plotting extracted events.","title":"find_event_peaks"},{"location":"api/#vitrocal.plotting.plot_average_event","text":"Plots the average detected event with the 25th and 75th percentiles shaded in. Parameters: combined ( DataFrame ) \u2013 A DataFrame with columns 'median', 'q1', and 'q3'. title ( str , default: 'Average Detected Event' ) \u2013 The title of the plot. ylabel ( str , default: 'df/F' ) \u2013 The label for the y-axis. xlabel ( str , default: 'Time' ) \u2013 The label for the x-axis. line_color ( str , default: 'black' ) \u2013 The color of the line. fill_color ( str , default: 'C0' ) \u2013 The color of the fill. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ): \"\"\" Plots the average detected event with the 25th and 75th percentiles shaded in. Args: combined (DataFrame): A DataFrame with columns 'median', 'q1', and 'q3'. title (str): The title of the plot. ylabel (str): The label for the y-axis. xlabel (str): The label for the x-axis. line_color (str): The color of the line. fill_color (str): The color of the fill. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () ax . plot ( combined . index , combined [ 'median' ], linestyle = 'dashed' , color = line_color ) ax . fill_between ( combined . index , combined [ 'q1' ], combined [ 'q3' ], alpha = .25 , color = fill_color ) ax . set_title ( title ) ax . set_ylabel ( ylabel ) ax . set_xlabel ( xlabel ) ax . spines [ 'right' ] . set_visible ( False ) ax . spines [ 'top' ] . set_visible ( False ) ax . spines [ 'left' ] . set_visible ( False ) ax . spines [ 'bottom' ] . set_visible ( False ) ax . set_yticks ([]) ax . set_xticks ([])","title":"plot_average_event"},{"location":"api/#vitrocal.plotting.plot_events","text":"Plots the detected events for a given ROI. Parameters: events_df ( DataFrame ) \u2013 A DataFrame with columns 'roi', 'time', and 'flourescence'. roi ( int , default: 0 ) \u2013 The region of interest to plot. title ( str , default: 'Detected Events for ROI' ) \u2013 The title of the plot. xlab ( str , default: 'Time (s)' ) \u2013 The label for the x-axis. ylab ( str , default: 'dF/F' ) \u2013 The label for the y-axis. color ( str , default: 'C0' ) \u2013 The color of the line. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ): \"\"\" Plots the detected events for a given ROI. Args: events_df (DataFrame): A DataFrame with columns 'roi', 'time', and 'flourescence'. roi (int): The region of interest to plot. title (str): The title of the plot. xlab (str): The label for the x-axis. ylab (str): The label for the y-axis. color (str): The color of the line. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () events = events_df [ events_df [ 'roi' ] == roi ] ax . plot ( events [ 'index' ], events [ 'flourescence' ], color = color ) ax . set_xlabel ( xlab ) ax . set_ylabel ( ylab ) ax . set_title ( title + ' ' + str ( roi ))","title":"plot_events"}]}