{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the repository for the VitroCal project! VitroCal is a Python-based toolbox for analyzing data collected through in vitro calcium imaging. The package is designed to be flexible and user-friendly. Quickstart Install from source git clone git@github.com:mpmbq2/vitrocal.git We recommend creating a virtual environment. cd vitrocal mamba env update -f environment.yml conda activate vitrocal python -m pip install . Example useage datacatalog = catalog.DataCatalog () df = datacatalog.load ( 'data' )","title":"Home"},{"location":"#quickstart","text":"","title":"Quickstart"},{"location":"#install-from-source","text":"git clone git@github.com:mpmbq2/vitrocal.git We recommend creating a virtual environment. cd vitrocal mamba env update -f environment.yml conda activate vitrocal python -m pip install .","title":"Install from source"},{"location":"#example-useage","text":"datacatalog = catalog.DataCatalog () df = datacatalog.load ( 'data' )","title":"Example useage"},{"location":"ParameterTune/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Tune Vitrocal Parameters import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.datasets import catalog , ExcelDataset from vitrocal.preprocessors import StandardPreprocessor from vitrocal.detectors import DerivativeDetector , StandardExtractor from vitrocal.analyzers import StandardAnalyzer from vitrocal.plotting import plot_events , plot_average_event Pull out functions from AnalyzeSingle.py and work with them interactively Load example data file def load_data ( fpath : str | os . PathLike , load_args : dict = {}) -& gt ; pd . DataFrame : \"\"\"Load single neuron output file. Args: fpath (str | os.PathLike): Path to single Excel spreadsheet. load_args (dict, optional): Passed to `pd.read_excel()`. Defaults to None. Returns: pd.DataFrame: Dataframe \"\"\" fname = os . path . basename ( fpath ) dataset = ExcelDataset . ExcelDataset ( fpath , load_args ) return dataset . load (), fname df , fname = load_data ( \"../data/01_raw/E Green.xlsx\" ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1.000 22.640 14.464 81.846 22.303 5.206 13.008 20.742 14.349 17.126 ... 4.038 19.026 6.572 17.669 7.024 2.347 23.887 42.383 4.802 7.620 0 2 21.593 13.584 81.234 19.634 4.756 10.206 17.576 14.729 16.779 ... 3.390 19.026 9.156 16.792 7.568 2.142 25.340 41.388 4.140 7.929 1 3 20.348 13.595 81.041 22.261 5.335 9.868 13.821 14.625 16.988 ... 4.179 18.215 7.307 17.280 7.383 2.056 27.561 41.679 3.816 6.994 2 4 22.938 13.941 81.420 21.579 5.410 9.857 13.642 14.422 16.672 ... 3.982 19.623 7.675 16.628 7.272 2.002 23.300 41.452 3.906 7.850 3 5 20.889 12.441 81.222 20.250 5.081 11.525 12.387 13.078 16.708 ... 4.201 19.561 5.383 20.522 7.516 1.527 19.236 46.553 4.277 7.748 4 6 21.691 14.711 81.017 21.015 5.553 11.386 17.477 13.776 16.634 ... 3.926 19.548 5.114 18.126 7.079 1.802 23.300 45.417 4.044 7.735 5 rows \u00d7 153 columns Note: you want to be super careful about loading your files and looking at them first. These files don't have a header, and sometimes they have numbered rows like this one. load_args = { 'header' : None , 'index_col' : 0 } df , fname = load_data ( \"../data/01_raw/E Green.xlsx\" , load_args ) Vitrocal is organized into three distinct modules for data analysis: * vitrocal.preprocessors * vitrocal.detectors * vitrocal.analyzers You'll want to explore the parameter space for each of these individually and assess the impacts different parameter combinations have on your data. See the documentation for details. Preprocess # change these fps = 1 / 2.5 bleach_period = 60 filter_frequency = None baseline_threshold = 10 # percent preprocess_window_size = 60 # seconds # instantiate the StandardPreprocess object with these parameters preprocessor = StandardPreprocessor ( frames_per_second = 1 / 2.5 , bleach_period = bleach_period , filter_frequency = filter_frequency , baseline_threshold = baseline_threshold , window_size = preprocess_window_size ) # call the object's `preprocess` method # see the documentation for other methods available processed = preprocessor . preprocess ( df ) No filter applied. Detect and Extract # change this threshold = 20 # percent detector = DerivativeDetector ( threshold ) detected = detector . detect ( processed ) Extract Note: the StandardExtractor class has a detect_and_extract method # change these window = ( 3 , 30 ) # seconds before and after threshold = 20 # percent extractor = StandardExtractor ( window = window , frames_per_second = fps , # defined above threshold = threshold ) events = extractor . extract ( processed , detected ) With FPS = 0.4, a window of (3, 30) seconds captures 1 frame(s) before and 12 frame(s) after each event. /Users/tony/Documents/phd/projects/other/vitrocal/vitrocal/detectors.py:137: PerformanceWarning: DataFrame is highly fragmented. This is usually the result of calling `frame.insert` many times, which has poor performance. Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()` identified[identified is False] = np.NaN # non-events Note: this method returns events as a Python dictionary. You can examine individual events, if you like: roi = 2 # events[roi] Analyze # change these upper_decay_bound = 0.8 # proportion lower_decay_bound = 0.2 # proportion analyzer = StandardAnalyzer ( upper_decay_bound = upper_decay_bound , lower_decay_bound = lower_decay_bound ) result , avg_result = analyzer . analyze ( events ) result . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi event peak upper lower decay 0 2 1.0 27.219529 21.297873269575085 2.423686623870037 18.874187 0 5 1.0 21.851080 6.71749433340203 -3.2533711260707254 9.970865 1 5 2.0 38.596155 15.092290988056458 1.5010871383174555 13.591204 2 5 3.0 37.804121 21.54067458187516 1.0369925070313724 20.503682 3 5 4.0 28.537583 17.316390264914933 NaN NaN avg_result . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi total_events average_peak average_decay 0 2 1 27.219529 18.874187 1 5 8 35.123731 14.355113 2 6 20 52.596420 21.558414 3 7 29 67.141770 30.643565 4 13 6 29.688055 14.325707 Plotting Jupyter notebooks are very helpful for making quick plots to confirm your intuition about an analysis problem. The syntax can be tricky: https://matplotlib.org Seaborn can make life a little easier, but you generally need to work with pandas.DataFrames for the input data. Average Events As an example, we might want to look at average intensity for a trace, or across all traces. global_average , roi_average , event_data = analyzer . find_average_event ( events ) global_average . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } q1 q3 median mean index 0 -3.009626 8.866823 1.295846 3.843737 1 24.651183 48.081438 33.998117 40.176931 2 3.184766 26.474071 12.826423 17.644599 3 3.056346 25.620465 12.851041 17.942584 4 2.526000 25.427945 11.794384 17.029477 roi_average . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi index q1 q3 median mean 0 2 0 -4.441242 -4.441242 -4.441242 -4.441242 1 2 1 27.219529 27.219529 27.219529 27.219529 2 2 2 21.297873 21.297873 21.297873 21.297873 3 2 3 14.791039 14.791039 14.791039 14.791039 4 2 4 21.044587 21.044587 21.044587 21.044587 plot_average_event ( global_average ) plt . show () selected_roi = 15 plot_average_event ( roi_average [ roi_average [ 'roi' ] == selected_roi ], title = 'Average Event for ROI {} ' . format ( selected_roi )) plt . show ()","title":"Example"},{"location":"ParameterTune/#tune-vitrocal-parameters","text":"import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from vitrocal.datasets import catalog , ExcelDataset from vitrocal.preprocessors import StandardPreprocessor from vitrocal.detectors import DerivativeDetector , StandardExtractor from vitrocal.analyzers import StandardAnalyzer from vitrocal.plotting import plot_events , plot_average_event Pull out functions from AnalyzeSingle.py and work with them interactively","title":"Tune Vitrocal Parameters"},{"location":"ParameterTune/#load-example-data-file","text":"def load_data ( fpath : str | os . PathLike , load_args : dict = {}) -& gt ; pd . DataFrame : \"\"\"Load single neuron output file. Args: fpath (str | os.PathLike): Path to single Excel spreadsheet. load_args (dict, optional): Passed to `pd.read_excel()`. Defaults to None. Returns: pd.DataFrame: Dataframe \"\"\" fname = os . path . basename ( fpath ) dataset = ExcelDataset . ExcelDataset ( fpath , load_args ) return dataset . load (), fname df , fname = load_data ( \"../data/01_raw/E Green.xlsx\" ) df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1.000 22.640 14.464 81.846 22.303 5.206 13.008 20.742 14.349 17.126 ... 4.038 19.026 6.572 17.669 7.024 2.347 23.887 42.383 4.802 7.620 0 2 21.593 13.584 81.234 19.634 4.756 10.206 17.576 14.729 16.779 ... 3.390 19.026 9.156 16.792 7.568 2.142 25.340 41.388 4.140 7.929 1 3 20.348 13.595 81.041 22.261 5.335 9.868 13.821 14.625 16.988 ... 4.179 18.215 7.307 17.280 7.383 2.056 27.561 41.679 3.816 6.994 2 4 22.938 13.941 81.420 21.579 5.410 9.857 13.642 14.422 16.672 ... 3.982 19.623 7.675 16.628 7.272 2.002 23.300 41.452 3.906 7.850 3 5 20.889 12.441 81.222 20.250 5.081 11.525 12.387 13.078 16.708 ... 4.201 19.561 5.383 20.522 7.516 1.527 19.236 46.553 4.277 7.748 4 6 21.691 14.711 81.017 21.015 5.553 11.386 17.477 13.776 16.634 ... 3.926 19.548 5.114 18.126 7.079 1.802 23.300 45.417 4.044 7.735 5 rows \u00d7 153 columns Note: you want to be super careful about loading your files and looking at them first. These files don't have a header, and sometimes they have numbered rows like this one. load_args = { 'header' : None , 'index_col' : 0 } df , fname = load_data ( \"../data/01_raw/E Green.xlsx\" , load_args ) Vitrocal is organized into three distinct modules for data analysis: * vitrocal.preprocessors * vitrocal.detectors * vitrocal.analyzers You'll want to explore the parameter space for each of these individually and assess the impacts different parameter combinations have on your data. See the documentation for details.","title":"Load example data file"},{"location":"ParameterTune/#preprocess","text":"# change these fps = 1 / 2.5 bleach_period = 60 filter_frequency = None baseline_threshold = 10 # percent preprocess_window_size = 60 # seconds # instantiate the StandardPreprocess object with these parameters preprocessor = StandardPreprocessor ( frames_per_second = 1 / 2.5 , bleach_period = bleach_period , filter_frequency = filter_frequency , baseline_threshold = baseline_threshold , window_size = preprocess_window_size ) # call the object's `preprocess` method # see the documentation for other methods available processed = preprocessor . preprocess ( df ) No filter applied.","title":"Preprocess"},{"location":"ParameterTune/#detect-and-extract","text":"# change this threshold = 20 # percent detector = DerivativeDetector ( threshold ) detected = detector . detect ( processed )","title":"Detect and Extract"},{"location":"ParameterTune/#extract","text":"Note: the StandardExtractor class has a detect_and_extract method # change these window = ( 3 , 30 ) # seconds before and after threshold = 20 # percent extractor = StandardExtractor ( window = window , frames_per_second = fps , # defined above threshold = threshold ) events = extractor . extract ( processed , detected ) With FPS = 0.4, a window of (3, 30) seconds captures 1 frame(s) before and 12 frame(s) after each event. /Users/tony/Documents/phd/projects/other/vitrocal/vitrocal/detectors.py:137: PerformanceWarning: DataFrame is highly fragmented. This is usually the result of calling `frame.insert` many times, which has poor performance. Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()` identified[identified is False] = np.NaN # non-events Note: this method returns events as a Python dictionary. You can examine individual events, if you like: roi = 2 # events[roi]","title":"Extract"},{"location":"ParameterTune/#analyze","text":"# change these upper_decay_bound = 0.8 # proportion lower_decay_bound = 0.2 # proportion analyzer = StandardAnalyzer ( upper_decay_bound = upper_decay_bound , lower_decay_bound = lower_decay_bound ) result , avg_result = analyzer . analyze ( events ) result . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi event peak upper lower decay 0 2 1.0 27.219529 21.297873269575085 2.423686623870037 18.874187 0 5 1.0 21.851080 6.71749433340203 -3.2533711260707254 9.970865 1 5 2.0 38.596155 15.092290988056458 1.5010871383174555 13.591204 2 5 3.0 37.804121 21.54067458187516 1.0369925070313724 20.503682 3 5 4.0 28.537583 17.316390264914933 NaN NaN avg_result . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi total_events average_peak average_decay 0 2 1 27.219529 18.874187 1 5 8 35.123731 14.355113 2 6 20 52.596420 21.558414 3 7 29 67.141770 30.643565 4 13 6 29.688055 14.325707","title":"Analyze"},{"location":"ParameterTune/#plotting","text":"Jupyter notebooks are very helpful for making quick plots to confirm your intuition about an analysis problem. The syntax can be tricky: https://matplotlib.org Seaborn can make life a little easier, but you generally need to work with pandas.DataFrames for the input data.","title":"Plotting"},{"location":"ParameterTune/#average-events","text":"As an example, we might want to look at average intensity for a trace, or across all traces. global_average , roi_average , event_data = analyzer . find_average_event ( events ) global_average . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } q1 q3 median mean index 0 -3.009626 8.866823 1.295846 3.843737 1 24.651183 48.081438 33.998117 40.176931 2 3.184766 26.474071 12.826423 17.644599 3 3.056346 25.620465 12.851041 17.942584 4 2.526000 25.427945 11.794384 17.029477 roi_average . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } roi index q1 q3 median mean 0 2 0 -4.441242 -4.441242 -4.441242 -4.441242 1 2 1 27.219529 27.219529 27.219529 27.219529 2 2 2 21.297873 21.297873 21.297873 21.297873 3 2 3 14.791039 14.791039 14.791039 14.791039 4 2 4 21.044587 21.044587 21.044587 21.044587 plot_average_event ( global_average ) plt . show () selected_roi = 15 plot_average_event ( roi_average [ roi_average [ 'roi' ] == selected_roi ], title = 'Average Event for ROI {} ' . format ( selected_roi )) plt . show ()","title":"Average Events"},{"location":"api/","text":"API Reference Top-level API for VitroCal. This is the file from which you can do: from vitrocal import some_function Use it to control the top-level API of your Python data science project. Catalog module for easy access to conf/catalog.yaml . AbstractCatalog Bases: ABC Abstract class for catalog. Source code in vitrocal/datasets/catalog.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class AbstractCatalog ( ABC ): \"\"\"Abstract class for catalog.\"\"\" @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load () load () abstractmethod Define loader for dataset. Returns: \u2013 Method Source code in vitrocal/datasets/catalog.py 20 21 22 23 24 25 26 27 @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load () parse_catalog () abstractmethod Define parser for catalog file. Returns: \u2013 Method. Source code in vitrocal/datasets/catalog.py 11 12 13 14 15 16 17 18 @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () DataCatalog Bases: AbstractCatalog Allows easy access to conf/catalog.yaml . Inspired by https://kedro.org. Source code in vitrocal/datasets/catalog.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class DataCatalog ( AbstractCatalog ): \"\"\"Allows easy access to `conf/catalog.yaml`. Inspired by https://kedro.org. \"\"\" def __init__ ( self , fpath = \"../../conf/catalog.yaml\" ): self . fpath = fpath self . datasets = self . parse_catalog () def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load () load ( dataset ) Loader function. Parameters: dataset \u2013 Valid dataset name. Returns: \u2013 Dataset. Source code in vitrocal/datasets/catalog.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load () parse_catalog () Parse catalog file. Returns: dict ( dict ) \u2013 Dataset dictionary. Source code in vitrocal/datasets/catalog.py 55 56 57 58 59 60 61 62 63 64 def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog ExcelDataset class definition ExcelDataset Bases: AbstractDataset ExcelDataset class. Source code in vitrocal/datasets/ExcelDataset.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ExcelDataset ( AbstractDataset ): \"\"\"ExcelDataset class.\"\"\" def __init__ ( self , filepath : str , load_args = {}): self . _filepath = PurePosixPath ( filepath ) self . _load_args = load_args def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) load () Loader function. Returns: DataFrame \u2013 pd.DataFrame: Dataframe. Source code in vitrocal/datasets/ExcelDataset.py 15 16 17 18 19 20 21 def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) save () Save function. Not yet implemented. Source code in vitrocal/datasets/ExcelDataset.py 23 24 25 26 def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) Abstract dataset classes. AbstractDataset Bases: ABC Abstract class for dataset. Source code in vitrocal/datasets/io.py 6 7 8 9 10 11 12 13 14 15 16 class AbstractDataset ( ABC ): \"\"\"Abstract class for dataset.\"\"\" @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () load () abstractmethod Loader base method. Source code in vitrocal/datasets/io.py 8 9 10 11 @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () save () abstractmethod Saver base method. Source code in vitrocal/datasets/io.py 13 14 15 16 @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () Preprocessor module. StandardPreprocessor Bases: BasePreprocessor Preprocessor object class. Attributes: frames_per_second ( int ) \u2013 Image aquisition rate. Defaults to None. filter_frequency ( float ) \u2013 Lowpass filter frequency (Hz). Defaults to None. filter_order ( int ) \u2013 Order passed to scipy.signal.bessel. Defaults to 1. window_size ( float ) \u2013 Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold ( float ) \u2013 Threshold below which to define baseline values (proportion). Defaults to None. bleach_period ( float ) \u2013 Source code in vitrocal/preprocessors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class StandardPreprocessor ( BasePreprocessor ): \"\"\"Preprocessor object class. Attributes: frames_per_second (int, optional): Image aquisition rate. Defaults to None. filter_frequency (float, optional): Lowpass filter frequency (Hz). Defaults to None. filter_order (int, optional): Order passed to scipy.signal.bessel. Defaults to 1. window_size (float, optional): Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold (float, optional): Threshold below which to define baseline values (proportion). Defaults to None. bleach_period (float, optional): Initial photobleaching period to be removed (seconds). Defaults to 60. \"\"\" def __init__ ( self , frames_per_second : int = None , filter_frequency : float = None , filter_order : int = 1 , window_size : float = 60 , baseline_threshold : float = None , bleach_period : float = 60 , column_minimum : int = None ): self . frames_per_second = frames_per_second self . filter_frequency = filter_frequency self . filter_order = filter_order self . window_size = window_size self . baseline_threshold = baseline_threshold self . bleach_period = bleach_period self . column_minimum = column_minimum def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) def _construct_bessel_filter ( self , filter_frequency : float , filter_order : int ): \"\"\"Apply scipy.signal.bessel filter. See https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.bessel.html Args: filter_frequency (float): Critical frequency. filter_order (int): Order of the filter. Returns: b,a: Numerator (b) and denominator (a) polynomials. \"\"\" # noqa: E501 b , a = bessel ( filter_order , filter_frequency ) return b , a def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100 baseline ( data ) Identify baseline fluoresence using a backward-looking rolling window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] compute_fluoresence_change ( data , baseline ) Compute percent change in flouresence from baseline. (data - baseline) / baseline * 100 Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) input dataframe. baseline ( DataFrame ) \u2013 m (images) x n (trace) baseline dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100 drop_frames ( data ) Drop frames for all traces. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with initial frames (rows) dropped. Source code in vitrocal/preprocessors.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) filter ( data ) Apply filter object backward and forward. Parameters: data ( DataFrame ) \u2013 ROI x image array. Returns: DataFrame \u2013 pd.DataFrame: Filtered output in the same shape as data . Source code in vitrocal/preprocessors.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) preprocess ( data ) Drop frames, filter, baseline, and compute flouresence change. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. Source code in vitrocal/preprocessors.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f Detector and extractor classes for event detection and extraction. DerivativeDetector Bases: BaseDetector Initialize derivative detector object. Attributes: threshold ( float ) \u2013 Minimum threshold (percent) to identify an event. Defaults to 20. Source code in vitrocal/detectors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class DerivativeDetector ( BaseDetector ): \"\"\"Initialize derivative detector object. Attributes: threshold (float, optional): Minimum threshold (percent) to identify an event. Defaults to 20. \"\"\" def __init__ ( self , threshold : float = 20 ): self . threshold = threshold def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold def _compute_derivative ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute element-wise difference. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Derivative dataframe. \"\"\" return data . diff () detect ( data ) Compute derivatives and detect threshold crossings. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. Source code in vitrocal/detectors.py 22 23 24 25 26 27 28 29 30 31 32 33 def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold StandardExtractor Bases: BaseExtractor Initialize event extractor object. Attributes: window ( Tuple [ int ] ) \u2013 Backward and forward window in seconds defining an event. frames_per_second ( int ) \u2013 Image aquisition rate.. Defaults to None. threshold ( float ) \u2013 Minimum percentile to identify an event. Passed to BaseDetector() . Defaults to 20. Source code in vitrocal/detectors.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class StandardExtractor ( BaseExtractor ): \"\"\"Initialize event extractor object. Attributes: window (Tuple[int]): Backward and forward window in seconds defining an event. frames_per_second (int, optional): Image aquisition rate.. Defaults to None. threshold (float, optional): Minimum percentile to identify an event. Passed to `BaseDetector()`. Defaults to 20. \"\"\" def __init__ ( self , window : Tuple [ int ], frames_per_second : int = None , threshold : float = 20 ): self . window = window self . frames_per_second = frames_per_second self . threshold = threshold def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events def _identify_events ( self , detected : pd . DataFrame ): \"\"\"Identify events (where derivative = 0). Args: detected (pd.DataFrame): Dataframe Returns: pd.DataFrame: Dataframe of identified events. \"\"\" identified = detected [ detected . diff () != 0 ] # only keep start of event identified [ identified is False ] = np . NaN # non-events return detected def _convert_window_to_frames ( self ) -> Tuple [ int , int ]: \"\"\"Convert window supplied in FPS to numbers of frames. Returns: Tuple[int, int]: Detection window expressed as numbers of frames backward and forward respectively. \"\"\" fps = self . frames_per_second window = tuple ( int ( w * fps ) for w in self . window ) print (( f \"With FPS = { self . frames_per_second } , a window of \" f \" { self . window } seconds captures { window [ 0 ] } frame(s) \" f \"before and { window [ 1 ] } frame(s) after each event.\" )) return window detect_and_extract ( data ) Compute derivatives and extract events. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: dict ( dict ) \u2013 Dictionary of events. Source code in vitrocal/detectors.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) extract ( data , detected ) Extract events using fixed window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. detected ( DataFrame ) \u2013 dataframe of detected events. Raises: ValueError \u2013 data and detected must be the of the same dimensions. Returns: dict ( dict ) \u2013 Extracted events. Source code in vitrocal/detectors.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events Module for analyzing extracted events. StandardAnalyzer Bases: BaseAnalyzer Initialize analyzer object. Attributes: upper_decay_bound ( float ) \u2013 Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound ( float ) \u2013 Proprtion of data to denote lower bound. Defaults to 0.2. Source code in vitrocal/analyzers.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 class StandardAnalyzer ( BaseAnalyzer ): \"\"\"Initialize analyzer object. Attributes: upper_decay_bound (float, optional): Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound (float, optional): Proprtion of data to denote lower bound. Defaults to 0.2. \"\"\" def __init__ ( self , upper_decay_bound : float = 0.8 , lower_decay_bound : float = 0.2 ): self . upper_decay_bound = upper_decay_bound self . lower_decay_bound = lower_decay_bound def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () # def find_average_event(self, events: dict) -> pd.Series: # \"\"\"Index-wise average events. # Args: # events (dict): Detected events from `StandardExtractor.detect_and_extract()` # Returns: # pd.DataFrame: Index-wise average event. # \"\"\" # combined = pd.Series() # for trac, values in events.items(): # for sequence in values: # tmp = pd.Series(sequence) # combined = pd.concat([combined, tmp], axis=1).agg(\"mean\", axis=1) # return combined.sort_index() def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data analyze ( events , drop_inf = True ) Return dataframe with event counts, peaks, and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: DataFrame \u2013 pd.DataFrame: Summary dataframe. Source code in vitrocal/analyzers.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results count_events ( events ) Count number of events for each trace. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Counts. Source code in vitrocal/analyzers.py 50 51 52 53 54 55 56 57 58 59 60 def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} find_average_decay ( decay ) Return summary metrics for each event grouped by ROI. Parameters: decay ( DataFrame ) \u2013 Output from StandardAnalyzer.find_event_decay() Returns: DataFrame \u2013 pd.DataFrame: Average metrics per ROI. Source code in vitrocal/analyzers.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () find_average_event ( events ) Find average events. Parameters: events ( dict ) \u2013 dictionary of events Returns: combined ( ( DataFrame , DataFrame ) ) \u2013 combined dataframe of quantiles event_data ( ( DataFrame , DataFrame ) ) \u2013 dataframe of events Source code in vitrocal/analyzers.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data find_event_decay ( events ) Find event peaks and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Summary dictionary. Source code in vitrocal/analyzers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary find_event_peaks ( events ) Find peak for each event. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Event peaks. Source code in vitrocal/analyzers.py 62 63 64 65 66 67 68 69 70 71 72 def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} Module for plotting extracted events. plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ) Plots the average detected event with the 25th and 75th percentiles shaded in. Parameters: combined ( DataFrame ) \u2013 A DataFrame with columns 'median', 'q1', and 'q3'. title ( str , default: 'Average Detected Event' ) \u2013 The title of the plot. ylabel ( str , default: 'df/F' ) \u2013 The label for the y-axis. xlabel ( str , default: 'Time' ) \u2013 The label for the x-axis. line_color ( str , default: 'black' ) \u2013 The color of the line. fill_color ( str , default: 'C0' ) \u2013 The color of the fill. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ): \"\"\" Plots the average detected event with the 25th and 75th percentiles shaded in. Args: combined (DataFrame): A DataFrame with columns 'median', 'q1', and 'q3'. title (str): The title of the plot. ylabel (str): The label for the y-axis. xlabel (str): The label for the x-axis. line_color (str): The color of the line. fill_color (str): The color of the fill. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () ax . plot ( combined . index , combined [ 'median' ], linestyle = 'dashed' , color = line_color ) ax . fill_between ( combined . index , combined [ 'q1' ], combined [ 'q3' ], alpha = .25 , color = fill_color ) ax . set_title ( title ) ax . set_ylabel ( ylabel ) ax . set_xlabel ( xlabel ) ax . spines [ 'right' ] . set_visible ( False ) ax . spines [ 'top' ] . set_visible ( False ) ax . spines [ 'left' ] . set_visible ( False ) ax . spines [ 'bottom' ] . set_visible ( False ) ax . set_yticks ([]) ax . set_xticks ([]) plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ) Plots the detected events for a given ROI. Parameters: events_df ( DataFrame ) \u2013 A DataFrame with columns 'roi', 'time', and 'flourescence'. roi ( int , default: 0 ) \u2013 The region of interest to plot. title ( str , default: 'Detected Events for ROI' ) \u2013 The title of the plot. xlab ( str , default: 'Time (s)' ) \u2013 The label for the x-axis. ylab ( str , default: 'dF/F' ) \u2013 The label for the y-axis. color ( str , default: 'C0' ) \u2013 The color of the line. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ): \"\"\" Plots the detected events for a given ROI. Args: events_df (DataFrame): A DataFrame with columns 'roi', 'time', and 'flourescence'. roi (int): The region of interest to plot. title (str): The title of the plot. xlab (str): The label for the x-axis. ylab (str): The label for the y-axis. color (str): The color of the line. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () events = events_df [ events_df [ 'roi' ] == roi ] ax . plot ( events [ 'index' ], events [ 'flourescence' ], color = color ) ax . set_xlabel ( xlab ) ax . set_ylabel ( ylab ) ax . set_title ( title + ' ' + str ( roi ))","title":"API Reference"},{"location":"api/#api-reference","text":"Top-level API for VitroCal. This is the file from which you can do: from vitrocal import some_function Use it to control the top-level API of your Python data science project. Catalog module for easy access to conf/catalog.yaml .","title":"API Reference"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog","text":"Bases: ABC Abstract class for catalog. Source code in vitrocal/datasets/catalog.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class AbstractCatalog ( ABC ): \"\"\"Abstract class for catalog.\"\"\" @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog () @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load ()","title":"AbstractCatalog"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog.load","text":"Define loader for dataset. Returns: \u2013 Method Source code in vitrocal/datasets/catalog.py 20 21 22 23 24 25 26 27 @abstractmethod def load ( self ): \"\"\"Define loader for dataset. Returns: Method \"\"\" return self . _load ()","title":"load"},{"location":"api/#vitrocal.datasets.catalog.AbstractCatalog.parse_catalog","text":"Define parser for catalog file. Returns: \u2013 Method. Source code in vitrocal/datasets/catalog.py 11 12 13 14 15 16 17 18 @abstractmethod def parse_catalog ( self ): \"\"\"Define parser for catalog file. Returns: Method. \"\"\" return self . _parse_catalog ()","title":"parse_catalog"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog","text":"Bases: AbstractCatalog Allows easy access to conf/catalog.yaml . Inspired by https://kedro.org. Source code in vitrocal/datasets/catalog.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class DataCatalog ( AbstractCatalog ): \"\"\"Allows easy access to `conf/catalog.yaml`. Inspired by https://kedro.org. \"\"\" def __init__ ( self , fpath = \"../../conf/catalog.yaml\" ): self . fpath = fpath self . datasets = self . parse_catalog () def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load ()","title":"DataCatalog"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog.load","text":"Loader function. Parameters: dataset \u2013 Valid dataset name. Returns: \u2013 Dataset. Source code in vitrocal/datasets/catalog.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def load ( self , dataset ): \"\"\"Loader function. Args: dataset: Valid dataset name. Returns: Dataset. \"\"\" _dataset = self . datasets [ dataset ] module = _get_dataset_type ( _dataset ) filepath = _dataset [ 'filepath' ] load_args = _dataset [ 'load_args' ] return module ( filepath , load_args ) . load ()","title":"load"},{"location":"api/#vitrocal.datasets.catalog.DataCatalog.parse_catalog","text":"Parse catalog file. Returns: dict ( dict ) \u2013 Dataset dictionary. Source code in vitrocal/datasets/catalog.py 55 56 57 58 59 60 61 62 63 64 def parse_catalog ( self ) -> dict : \"\"\"Parse catalog file. Returns: dict: Dataset dictionary. \"\"\" fpath = self . fpath with open ( fpath , 'r' ) as file : catalog = yaml . safe_load ( file ) return catalog ExcelDataset class definition","title":"parse_catalog"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset","text":"Bases: AbstractDataset ExcelDataset class. Source code in vitrocal/datasets/ExcelDataset.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ExcelDataset ( AbstractDataset ): \"\"\"ExcelDataset class.\"\"\" def __init__ ( self , filepath : str , load_args = {}): self . _filepath = PurePosixPath ( filepath ) self . _load_args = load_args def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args ) def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError )","title":"ExcelDataset"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset.load","text":"Loader function. Returns: DataFrame \u2013 pd.DataFrame: Dataframe. Source code in vitrocal/datasets/ExcelDataset.py 15 16 17 18 19 20 21 def load ( self ) -> pd . DataFrame : \"\"\"Loader function. Returns: pd.DataFrame: Dataframe. \"\"\" return pd . read_excel ( self . _filepath , ** self . _load_args )","title":"load"},{"location":"api/#vitrocal.datasets.ExcelDataset.ExcelDataset.save","text":"Save function. Not yet implemented. Source code in vitrocal/datasets/ExcelDataset.py 23 24 25 26 def save ( self ): \"\"\"Save function. Not yet implemented. \"\"\" raise ( NotImplementedError ) Abstract dataset classes.","title":"save"},{"location":"api/#vitrocal.datasets.io.AbstractDataset","text":"Bases: ABC Abstract class for dataset. Source code in vitrocal/datasets/io.py 6 7 8 9 10 11 12 13 14 15 16 class AbstractDataset ( ABC ): \"\"\"Abstract class for dataset.\"\"\" @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load () @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save ()","title":"AbstractDataset"},{"location":"api/#vitrocal.datasets.io.AbstractDataset.load","text":"Loader base method. Source code in vitrocal/datasets/io.py 8 9 10 11 @abstractmethod def load ( self ): \"\"\"Loader base method.\"\"\" return self . _load ()","title":"load"},{"location":"api/#vitrocal.datasets.io.AbstractDataset.save","text":"Saver base method. Source code in vitrocal/datasets/io.py 13 14 15 16 @abstractmethod def save ( self ): \"\"\"Saver base method.\"\"\" return self . _save () Preprocessor module.","title":"save"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor","text":"Bases: BasePreprocessor Preprocessor object class. Attributes: frames_per_second ( int ) \u2013 Image aquisition rate. Defaults to None. filter_frequency ( float ) \u2013 Lowpass filter frequency (Hz). Defaults to None. filter_order ( int ) \u2013 Order passed to scipy.signal.bessel. Defaults to 1. window_size ( float ) \u2013 Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold ( float ) \u2013 Threshold below which to define baseline values (proportion). Defaults to None. bleach_period ( float ) \u2013 Source code in vitrocal/preprocessors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class StandardPreprocessor ( BasePreprocessor ): \"\"\"Preprocessor object class. Attributes: frames_per_second (int, optional): Image aquisition rate. Defaults to None. filter_frequency (float, optional): Lowpass filter frequency (Hz). Defaults to None. filter_order (int, optional): Order passed to scipy.signal.bessel. Defaults to 1. window_size (float, optional): Size of rolling window to construct baseline values. Defaults to 60. baseline_threshold (float, optional): Threshold below which to define baseline values (proportion). Defaults to None. bleach_period (float, optional): Initial photobleaching period to be removed (seconds). Defaults to 60. \"\"\" def __init__ ( self , frames_per_second : int = None , filter_frequency : float = None , filter_order : int = 1 , window_size : float = 60 , baseline_threshold : float = None , bleach_period : float = 60 , column_minimum : int = None ): self . frames_per_second = frames_per_second self . filter_frequency = filter_frequency self . filter_order = filter_order self . window_size = window_size self . baseline_threshold = baseline_threshold self . bleach_period = bleach_period self . column_minimum = column_minimum def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) ) def _construct_bessel_filter ( self , filter_frequency : float , filter_order : int ): \"\"\"Apply scipy.signal.bessel filter. See https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.bessel.html Args: filter_frequency (float): Critical frequency. filter_order (int): Order of the filter. Returns: b,a: Numerator (b) and denominator (a) polynomials. \"\"\" # noqa: E501 b , a = bessel ( filter_order , filter_frequency ) return b , a def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered ) def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ] def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100","title":"StandardPreprocessor"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.baseline","text":"Identify baseline fluoresence using a backward-looking rolling window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def baseline ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\" Identify baseline fluoresence using a backward-looking rolling window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" window_frames = int ( self . window_size * self . frames_per_second ) # turn this into a FixedBackwardwindowIndexer by reversing the dataframe indexer = FixedForwardWindowIndexer ( window_size = window_frames ) rev_data = data . iloc [:: - 1 ] baseline = ( rev_data . rolling ( window = indexer , min_periods = 1 ) . apply ( np . percentile , kwargs = { 'q' : self . baseline_threshold }) ) return baseline . iloc [:: - 1 ]","title":"baseline"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.compute_fluoresence_change","text":"Compute percent change in flouresence from baseline. (data - baseline) / baseline * 100 Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) input dataframe. baseline ( DataFrame ) \u2013 m (images) x n (trace) baseline dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with same dimensions as input data. Source code in vitrocal/preprocessors.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def compute_fluoresence_change ( self , data : pd . DataFrame , baseline : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute percent change in flouresence from baseline. `(data - baseline) / baseline * 100` Args: data (pd.DataFrame): m (images) x n (trace) input dataframe. baseline (pd.DataFrame): m (images) x n (trace) baseline dataframe. Returns: pd.DataFrame: Dataframe with same dimensions as input data. \"\"\" return ( data - baseline ) / baseline * 100","title":"compute_fluoresence_change"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.drop_frames","text":"Drop frames for all traces. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Dataframe with initial frames (rows) dropped. Source code in vitrocal/preprocessors.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def drop_frames ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames for all traces. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Dataframe with initial frames (rows) dropped. \"\"\" n_frames = len ( data ) frame_times = np . arange ( n_frames ) * 1 / self . frames_per_second initial_frames = len ( frame_times [ frame_times <= self . bleach_period ]) return ( data . iloc [ initial_frames :] . reset_index ( drop = True ) )","title":"drop_frames"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.filter","text":"Apply filter object backward and forward. Parameters: data ( DataFrame ) \u2013 ROI x image array. Returns: DataFrame \u2013 pd.DataFrame: Filtered output in the same shape as data . Source code in vitrocal/preprocessors.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def filter ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Apply filter object backward and forward. Args: data (pd.DataFrame): ROI x image array. Returns: pd.DataFrame: Filtered output in the same shape as `data`. \"\"\" if self . filter_frequency is None : print ( \"No filter applied.\" ) return data else : b , a = self . _construct_bessel_filter ( self . filter_frequency , self . filter_order ) filtered = filtfilt ( b , a , data ) return pd . DataFrame ( filtered )","title":"filter"},{"location":"api/#vitrocal.preprocessors.StandardPreprocessor.preprocess","text":"Drop frames, filter, baseline, and compute flouresence change. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. Source code in vitrocal/preprocessors.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def preprocess ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Drop frames, filter, baseline, and compute flouresence change. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Flouresence change dataframe with thes same dimensions as input data. \"\"\" data = self . drop_frames ( data ) data = self . filter ( data ) baseline = self . baseline ( data ) d_f = self . compute_fluoresence_change ( data , baseline ) return d_f Detector and extractor classes for event detection and extraction.","title":"preprocess"},{"location":"api/#vitrocal.detectors.DerivativeDetector","text":"Bases: BaseDetector Initialize derivative detector object. Attributes: threshold ( float ) \u2013 Minimum threshold (percent) to identify an event. Defaults to 20. Source code in vitrocal/detectors.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class DerivativeDetector ( BaseDetector ): \"\"\"Initialize derivative detector object. Attributes: threshold (float, optional): Minimum threshold (percent) to identify an event. Defaults to 20. \"\"\" def __init__ ( self , threshold : float = 20 ): self . threshold = threshold def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold def _compute_derivative ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute element-wise difference. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Derivative dataframe. \"\"\" return data . diff ()","title":"DerivativeDetector"},{"location":"api/#vitrocal.detectors.DerivativeDetector.detect","text":"Compute derivatives and detect threshold crossings. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: DataFrame \u2013 pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. Source code in vitrocal/detectors.py 22 23 24 25 26 27 28 29 30 31 32 33 def detect ( self , data : pd . DataFrame ) -> pd . DataFrame : \"\"\"Compute derivatives and detect threshold crossings. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: pd.DataFrame: Indicator (Boolean) dataframe of the same dimensions as input data. \"\"\" derivative = self . _compute_derivative ( data ) return derivative > self . threshold","title":"detect"},{"location":"api/#vitrocal.detectors.StandardExtractor","text":"Bases: BaseExtractor Initialize event extractor object. Attributes: window ( Tuple [ int ] ) \u2013 Backward and forward window in seconds defining an event. frames_per_second ( int ) \u2013 Image aquisition rate.. Defaults to None. threshold ( float ) \u2013 Minimum percentile to identify an event. Passed to BaseDetector() . Defaults to 20. Source code in vitrocal/detectors.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class StandardExtractor ( BaseExtractor ): \"\"\"Initialize event extractor object. Attributes: window (Tuple[int]): Backward and forward window in seconds defining an event. frames_per_second (int, optional): Image aquisition rate.. Defaults to None. threshold (float, optional): Minimum percentile to identify an event. Passed to `BaseDetector()`. Defaults to 20. \"\"\" def __init__ ( self , window : Tuple [ int ], frames_per_second : int = None , threshold : float = 20 ): self . window = window self . frames_per_second = frames_per_second self . threshold = threshold def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected ) def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events def _identify_events ( self , detected : pd . DataFrame ): \"\"\"Identify events (where derivative = 0). Args: detected (pd.DataFrame): Dataframe Returns: pd.DataFrame: Dataframe of identified events. \"\"\" identified = detected [ detected . diff () != 0 ] # only keep start of event identified [ identified is False ] = np . NaN # non-events return detected def _convert_window_to_frames ( self ) -> Tuple [ int , int ]: \"\"\"Convert window supplied in FPS to numbers of frames. Returns: Tuple[int, int]: Detection window expressed as numbers of frames backward and forward respectively. \"\"\" fps = self . frames_per_second window = tuple ( int ( w * fps ) for w in self . window ) print (( f \"With FPS = { self . frames_per_second } , a window of \" f \" { self . window } seconds captures { window [ 0 ] } frame(s) \" f \"before and { window [ 1 ] } frame(s) after each event.\" )) return window","title":"StandardExtractor"},{"location":"api/#vitrocal.detectors.StandardExtractor.detect_and_extract","text":"Compute derivatives and extract events. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. Returns: dict ( dict ) \u2013 Dictionary of events. Source code in vitrocal/detectors.py 68 69 70 71 72 73 74 75 76 77 78 79 80 def detect_and_extract ( self , data : pd . DataFrame ) -> dict : \"\"\"Compute derivatives and extract events. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. Returns: dict: Dictionary of events. \"\"\" detector = DerivativeDetector ( threshold = self . threshold ) detected = detector . detect ( data ) return self . extract ( data , detected )","title":"detect_and_extract"},{"location":"api/#vitrocal.detectors.StandardExtractor.extract","text":"Extract events using fixed window. Parameters: data ( DataFrame ) \u2013 m (images) x n (trace) dataframe. detected ( DataFrame ) \u2013 dataframe of detected events. Raises: ValueError \u2013 data and detected must be the of the same dimensions. Returns: dict ( dict ) \u2013 Extracted events. Source code in vitrocal/detectors.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 def extract ( self , data : pd . DataFrame , detected : pd . DataFrame ) -> dict : \"\"\"Extract events using fixed window. Args: data (pd.DataFrame): m (images) x n (trace) dataframe. detected (pd.DataFrame): dataframe of detected events. Raises: ValueError: `data` and `detected` must be the of the same dimensions. Returns: dict: Extracted events. \"\"\" if data . shape != detected . shape : raise ValueError ( \"Data and event dataframes must be the same dimensions.\" ) identified = self . _identify_events ( detected ) window = self . _convert_window_to_frames () extracted_events = {} for column in data . columns : event_starts = identified [ column ] roi = data [ column ] indices = event_starts [ event_starts ] . index events = [] for index in indices : min_idx = index - window [ 0 ] max_idx = index + window [ 1 ] start = min_idx if min_idx > 0 else 0 stop = max_idx if max_idx < len ( roi ) else len ( roi ) events . append ( roi . loc [ start : stop ]) extracted_events [ roi . name ] = events return extracted_events Module for analyzing extracted events.","title":"extract"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer","text":"Bases: BaseAnalyzer Initialize analyzer object. Attributes: upper_decay_bound ( float ) \u2013 Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound ( float ) \u2013 Proprtion of data to denote lower bound. Defaults to 0.2. Source code in vitrocal/analyzers.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 class StandardAnalyzer ( BaseAnalyzer ): \"\"\"Initialize analyzer object. Attributes: upper_decay_bound (float, optional): Proportion of data to denote upper bound. Defaults to 0.8. lower_decay_bound (float, optional): Proprtion of data to denote lower bound. Defaults to 0.2. \"\"\" def __init__ ( self , upper_decay_bound : float = 0.8 , lower_decay_bound : float = 0.2 ): self . upper_decay_bound = upper_decay_bound self . lower_decay_bound = lower_decay_bound def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()} def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index () # def find_average_event(self, events: dict) -> pd.Series: # \"\"\"Index-wise average events. # Args: # events (dict): Detected events from `StandardExtractor.detect_and_extract()` # Returns: # pd.DataFrame: Index-wise average event. # \"\"\" # combined = pd.Series() # for trac, values in events.items(): # for sequence in values: # tmp = pd.Series(sequence) # combined = pd.concat([combined, tmp], axis=1).agg(\"mean\", axis=1) # return combined.sort_index() def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data","title":"StandardAnalyzer"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.analyze","text":"Return dataframe with event counts, peaks, and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: DataFrame \u2013 pd.DataFrame: Summary dataframe. Source code in vitrocal/analyzers.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def analyze ( self , events : dict , drop_inf = True ) -> pd . DataFrame : \"\"\"Return dataframe with event counts, peaks, and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: pd.DataFrame: Summary dataframe. \"\"\" decay = self . find_event_decay ( events ) results = pd . DataFrame () for roi , values in decay . items (): tmp = pd . DataFrame ( values ) tmp . insert ( 0 , 'roi' , roi ) tmp = tmp . replace ([ np . inf , - np . inf ], np . nan ) # replace inf with missing results = pd . concat ([ results , tmp ]) avg_results = self . find_average_decay ( results ) return results , avg_results","title":"analyze"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.count_events","text":"Count number of events for each trace. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Counts. Source code in vitrocal/analyzers.py 50 51 52 53 54 55 56 57 58 59 60 def count_events ( self , events : dict ) -> dict : \"\"\"Count number of events for each trace. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Counts. \"\"\" return { k : len ( v ) for k , v in events . items ()}","title":"count_events"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_average_decay","text":"Return summary metrics for each event grouped by ROI. Parameters: decay ( DataFrame ) \u2013 Output from StandardAnalyzer.find_event_decay() Returns: DataFrame \u2013 pd.DataFrame: Average metrics per ROI. Source code in vitrocal/analyzers.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def find_average_decay ( self , decay : pd . DataFrame ) -> pd . DataFrame : \"\"\"Return summary metrics for each event grouped by ROI. Args: decay (pd.DataFrame): Output from `StandardAnalyzer.find_event_decay()` Returns: pd.DataFrame: Average metrics per ROI. \"\"\" agg_funcs = { 'total_events' : pd . NamedAgg ( column = 'event' , aggfunc = 'count' ), 'average_peak' : pd . NamedAgg ( column = 'peak' , aggfunc = 'mean' ), 'average_decay' : pd . NamedAgg ( column = 'decay' , aggfunc = 'mean' ) } avg = decay . groupby ([ 'roi' ]) . agg ( total_events = agg_funcs [ 'total_events' ], average_peak = agg_funcs [ 'average_peak' ], average_decay = agg_funcs [ 'average_decay' ] ) return avg . reset_index ()","title":"find_average_decay"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_average_event","text":"Find average events. Parameters: events ( dict ) \u2013 dictionary of events Returns: combined ( ( DataFrame , DataFrame ) ) \u2013 combined dataframe of quantiles event_data ( ( DataFrame , DataFrame ) ) \u2013 dataframe of events Source code in vitrocal/analyzers.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def find_average_event ( self , events : dict ) -> ( pd . DataFrame , pd . DataFrame ): \"\"\" Find average events. Args: events: dictionary of events Returns: combined: combined dataframe of quantiles event_data: dataframe of events \"\"\" # get maximum event duration max_length = 0 for roi , data in events . items (): for event in data : if len ( event ) > max_length : max_length = len ( event ) # combine events into a single dataframe event_count = 0 event_data = pd . DataFrame () for roi , data in events . items (): for event in data : event = list ( event ) if len ( event ) < max_length : event . extend ([ np . nan ] * ( max_length - len ( event ))) tmp = pd . DataFrame ({ 'flourescence' : event }) tmp [ 'index' ] = range ( len ( tmp )) tmp [ 'roi' ] = roi event_data = pd . concat ([ event_data , tmp ], axis = 0 ) event_count += 1 def _aggregate_events ( x : pd . DataFrame ): q1 = x . quantile ( .25 ) q3 = x . quantile ( .75 ) median = x . median () mean = x . mean () combined = pd . concat ([ q1 , q3 , median , mean ], axis = 1 ) combined . columns = [ 'q1' , 'q3' , 'median' , 'mean' ] return combined global_average = _aggregate_events ( event_data . drop ( columns = 'roi' ) . groupby ( 'index' )) roi_average = _aggregate_events ( event_data . groupby ([ 'roi' , 'index' ])) return global_average , roi_average . reset_index (), event_data","title":"find_average_event"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_event_decay","text":"Find event peaks and decay. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Summary dictionary. Source code in vitrocal/analyzers.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def find_event_decay ( self , events : dict ) -> dict : \"\"\"Find event peaks and decay. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Summary dictionary. \"\"\" def _handle_decay_values ( x : list ) -> float : \"\"\"Handle decay values. Args: x (list): Detected bounds. Returns: float: Single bound. \"\"\" if len ( x ) >= 1 : bound = x [ 0 ] else : bound = np . nan return bound summary = {} for roi , sequence in events . items (): sequence_summary = [] event_count = 1 for event in sequence : peak = np . max ( event ) peak_index = np . argmax ( event ) upper_bound = peak * self . upper_decay_bound lower_bound = peak * self . lower_decay_bound upper_bounds = [] lower_bounds = [] for value in np . nditer ( event [ peak_index :]): if value <= upper_bound and value > lower_bound : upper_bounds . append ( value ) if value <= lower_bound : lower_bounds . append ( value ) upper = _handle_decay_values ( upper_bounds ) lower = _handle_decay_values ( lower_bounds ) res = { 'event' : event_count , 'peak' : peak , 'upper' : upper , 'lower' : lower , 'decay' : upper - lower } event_count += 1 sequence_summary . append ( res ) summary [ roi ] = sequence_summary return summary","title":"find_event_decay"},{"location":"api/#vitrocal.analyzers.StandardAnalyzer.find_event_peaks","text":"Find peak for each event. Parameters: events ( dict ) \u2013 Detected events from StandardExtractor.detect_and_extract() Returns: dict ( dict ) \u2013 Event peaks. Source code in vitrocal/analyzers.py 62 63 64 65 66 67 68 69 70 71 72 def find_event_peaks ( self , events : dict ) -> dict : \"\"\"Find peak for each event. Args: events (dict): Detected events from `StandardExtractor.detect_and_extract()` Returns: dict: Event peaks. \"\"\" return { k : [ np . max ( ev ) for ev in v ] for k , v in events . items ()} Module for plotting extracted events.","title":"find_event_peaks"},{"location":"api/#vitrocal.plotting.plot_average_event","text":"Plots the average detected event with the 25th and 75th percentiles shaded in. Parameters: combined ( DataFrame ) \u2013 A DataFrame with columns 'median', 'q1', and 'q3'. title ( str , default: 'Average Detected Event' ) \u2013 The title of the plot. ylabel ( str , default: 'df/F' ) \u2013 The label for the y-axis. xlabel ( str , default: 'Time' ) \u2013 The label for the x-axis. line_color ( str , default: 'black' ) \u2013 The color of the line. fill_color ( str , default: 'C0' ) \u2013 The color of the fill. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def plot_average_event ( combined , title = 'Average Detected Event' , ylabel = 'df/F' , xlabel = 'Time' , line_color = 'black' , fill_color = 'C0' , ax = None ): \"\"\" Plots the average detected event with the 25th and 75th percentiles shaded in. Args: combined (DataFrame): A DataFrame with columns 'median', 'q1', and 'q3'. title (str): The title of the plot. ylabel (str): The label for the y-axis. xlabel (str): The label for the x-axis. line_color (str): The color of the line. fill_color (str): The color of the fill. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () ax . plot ( combined . index , combined [ 'median' ], linestyle = 'dashed' , color = line_color ) ax . fill_between ( combined . index , combined [ 'q1' ], combined [ 'q3' ], alpha = .25 , color = fill_color ) ax . set_title ( title ) ax . set_ylabel ( ylabel ) ax . set_xlabel ( xlabel ) ax . spines [ 'right' ] . set_visible ( False ) ax . spines [ 'top' ] . set_visible ( False ) ax . spines [ 'left' ] . set_visible ( False ) ax . spines [ 'bottom' ] . set_visible ( False ) ax . set_yticks ([]) ax . set_xticks ([])","title":"plot_average_event"},{"location":"api/#vitrocal.plotting.plot_events","text":"Plots the detected events for a given ROI. Parameters: events_df ( DataFrame ) \u2013 A DataFrame with columns 'roi', 'time', and 'flourescence'. roi ( int , default: 0 ) \u2013 The region of interest to plot. title ( str , default: 'Detected Events for ROI' ) \u2013 The title of the plot. xlab ( str , default: 'Time (s)' ) \u2013 The label for the x-axis. ylab ( str , default: 'dF/F' ) \u2013 The label for the y-axis. color ( str , default: 'C0' ) \u2013 The color of the line. ax ( Axes , default: None ) \u2013 The axes to plot on. If None, a new figure is created. Source code in vitrocal/plotting.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def plot_events ( events_df , roi = 0 , title = 'Detected Events for ROI' , xlab = 'Time (s)' , ylab = 'dF/F' , color = 'C0' , ax = None ): \"\"\" Plots the detected events for a given ROI. Args: events_df (DataFrame): A DataFrame with columns 'roi', 'time', and 'flourescence'. roi (int): The region of interest to plot. title (str): The title of the plot. xlab (str): The label for the x-axis. ylab (str): The label for the y-axis. color (str): The color of the line. ax (Axes): The axes to plot on. If None, a new figure is created. \"\"\" if ax is None : fig , ax = plt . subplots () events = events_df [ events_df [ 'roi' ] == roi ] ax . plot ( events [ 'index' ], events [ 'flourescence' ], color = color ) ax . set_xlabel ( xlab ) ax . set_ylabel ( ylab ) ax . set_title ( title + ' ' + str ( roi ))","title":"plot_events"}]}